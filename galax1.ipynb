{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4RB7GVHUjKG",
        "outputId": "1dcc7926-c601-465c-ff3e-181ddaa006b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'custom-pytorch-lightning-module'...\n",
            "remote: Enumerating objects: 46, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 46 (delta 25), reused 28 (delta 13), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (46/46), 22.47 KiB | 442.00 KiB/s, done.\n",
            "Resolving deltas: 100% (25/25), done.\n",
            "Cloning into 'pytorch-blocks'...\n",
            "remote: Enumerating objects: 29, done.\u001b[K\n",
            "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 29 (delta 15), reused 18 (delta 8), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (29/29), 20.19 KiB | 1.12 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/lucas-battisti/custom-pytorch-lightning-module.git\n",
        "!mv \"custom-pytorch-lightning-module/modules.py\" \"modules.py\"\n",
        "!rm -rf \"custom-pytorch-lightning-module\"\n",
        "\n",
        "\n",
        "\n",
        "!git clone https://github.com/lucas-battisti/pytorch-blocks.git\n",
        "!mv \"pytorch-blocks/blocks.py\" \"blocks.py\"\n",
        "!rm -rf \"pytorch-blocks\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "epjII3SgUjKL"
      },
      "outputs": [],
      "source": [
        "import dt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('data/galax.csv').drop('ID', axis=1).astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>e_FUVmag</th>\n",
              "      <th>e_NUVmag</th>\n",
              "      <th>e_u_PStotal</th>\n",
              "      <th>e_J0378_PStotal</th>\n",
              "      <th>e_J0395_PStotal</th>\n",
              "      <th>e_J0410_PStotal</th>\n",
              "      <th>e_J0430_PStotal</th>\n",
              "      <th>e_g_PStotal</th>\n",
              "      <th>e_J0515_PStotal</th>\n",
              "      <th>e_r_PStotal</th>\n",
              "      <th>e_J0660_PStotal</th>\n",
              "      <th>e_i_PStotal</th>\n",
              "      <th>e_J0861_PStotal</th>\n",
              "      <th>e_z_PStotal</th>\n",
              "      <th>e_W1_MAG</th>\n",
              "      <th>e_W2_MAG</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.224955</td>\n",
              "      <td>0.311987</td>\n",
              "      <td>0.518295</td>\n",
              "      <td>0.194772</td>\n",
              "      <td>0.245713</td>\n",
              "      <td>0.041893</td>\n",
              "      <td>0.091243</td>\n",
              "      <td>0.025094</td>\n",
              "      <td>0.029657</td>\n",
              "      <td>0.023942</td>\n",
              "      <td>0.055467</td>\n",
              "      <td>0.036479</td>\n",
              "      <td>0.033687</td>\n",
              "      <td>0.083541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.452150</td>\n",
              "      <td>0.671358</td>\n",
              "      <td>0.382968</td>\n",
              "      <td>1.782604</td>\n",
              "      <td>0.585214</td>\n",
              "      <td>0.124910</td>\n",
              "      <td>0.304120</td>\n",
              "      <td>0.064142</td>\n",
              "      <td>0.059612</td>\n",
              "      <td>0.048313</td>\n",
              "      <td>0.102840</td>\n",
              "      <td>0.068152</td>\n",
              "      <td>0.025455</td>\n",
              "      <td>0.062376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.853746</td>\n",
              "      <td>24.218925</td>\n",
              "      <td>2.501554</td>\n",
              "      <td>0.662034</td>\n",
              "      <td>0.650283</td>\n",
              "      <td>0.137526</td>\n",
              "      <td>0.152992</td>\n",
              "      <td>0.092161</td>\n",
              "      <td>0.250096</td>\n",
              "      <td>0.123786</td>\n",
              "      <td>0.019780</td>\n",
              "      <td>0.081629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.673750</td>\n",
              "      <td>0.911359</td>\n",
              "      <td>0.611246</td>\n",
              "      <td>0.835895</td>\n",
              "      <td>0.634541</td>\n",
              "      <td>0.132246</td>\n",
              "      <td>0.293990</td>\n",
              "      <td>0.064867</td>\n",
              "      <td>0.061165</td>\n",
              "      <td>0.047712</td>\n",
              "      <td>0.101811</td>\n",
              "      <td>0.062711</td>\n",
              "      <td>0.027340</td>\n",
              "      <td>0.058215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.727081</td>\n",
              "      <td>0.447041</td>\n",
              "      <td>1.601313</td>\n",
              "      <td>0.658014</td>\n",
              "      <td>0.204889</td>\n",
              "      <td>0.070558</td>\n",
              "      <td>0.167561</td>\n",
              "      <td>0.042762</td>\n",
              "      <td>0.063853</td>\n",
              "      <td>0.035506</td>\n",
              "      <td>0.072106</td>\n",
              "      <td>0.049442</td>\n",
              "      <td>0.020226</td>\n",
              "      <td>0.054294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>324068</th>\n",
              "      <td>0.4851</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>2.584847</td>\n",
              "      <td>1.625167</td>\n",
              "      <td>2.574174</td>\n",
              "      <td>0.459246</td>\n",
              "      <td>0.648415</td>\n",
              "      <td>0.106416</td>\n",
              "      <td>0.284852</td>\n",
              "      <td>0.066846</td>\n",
              "      <td>0.064942</td>\n",
              "      <td>0.065221</td>\n",
              "      <td>0.119365</td>\n",
              "      <td>0.117191</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>324069</th>\n",
              "      <td>0.1047</td>\n",
              "      <td>0.0587</td>\n",
              "      <td>0.168559</td>\n",
              "      <td>0.303243</td>\n",
              "      <td>0.330396</td>\n",
              "      <td>0.390139</td>\n",
              "      <td>0.248238</td>\n",
              "      <td>0.069870</td>\n",
              "      <td>0.143726</td>\n",
              "      <td>0.037100</td>\n",
              "      <td>0.040685</td>\n",
              "      <td>0.031847</td>\n",
              "      <td>0.057521</td>\n",
              "      <td>0.044997</td>\n",
              "      <td>0.012762</td>\n",
              "      <td>0.044740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>324070</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.007946</td>\n",
              "      <td>0.881726</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.336982</td>\n",
              "      <td>1.126299</td>\n",
              "      <td>0.116354</td>\n",
              "      <td>0.181017</td>\n",
              "      <td>0.036185</td>\n",
              "      <td>0.028266</td>\n",
              "      <td>0.018727</td>\n",
              "      <td>0.026390</td>\n",
              "      <td>0.021848</td>\n",
              "      <td>0.009996</td>\n",
              "      <td>0.021091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>324071</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.650383</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.959220</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.318630</td>\n",
              "      <td>0.995016</td>\n",
              "      <td>0.114878</td>\n",
              "      <td>0.110119</td>\n",
              "      <td>0.081381</td>\n",
              "      <td>0.182333</td>\n",
              "      <td>0.112433</td>\n",
              "      <td>0.054559</td>\n",
              "      <td>0.129773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>324072</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.044804</td>\n",
              "      <td>1.964511</td>\n",
              "      <td>5.021149</td>\n",
              "      <td>2.632960</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.938834</td>\n",
              "      <td>1.200194</td>\n",
              "      <td>0.398826</td>\n",
              "      <td>0.737208</td>\n",
              "      <td>3.347102</td>\n",
              "      <td>0.586793</td>\n",
              "      <td>0.353271</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>324073 rows × 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        e_FUVmag  e_NUVmag  e_u_PStotal  e_J0378_PStotal  e_J0395_PStotal  \\\n",
              "0            NaN       NaN     0.224955         0.311987         0.518295   \n",
              "1            NaN       NaN     0.452150         0.671358         0.382968   \n",
              "2            NaN       NaN          NaN              NaN         0.853746   \n",
              "3            NaN       NaN     2.673750         0.911359         0.611246   \n",
              "4            NaN       NaN     0.727081         0.447041         1.601313   \n",
              "...          ...       ...          ...              ...              ...   \n",
              "324068    0.4851    0.1726     2.584847         1.625167         2.574174   \n",
              "324069    0.1047    0.0587     0.168559         0.303243         0.330396   \n",
              "324070       NaN       NaN     1.007946         0.881726              NaN   \n",
              "324071       NaN       NaN          NaN         6.650383              NaN   \n",
              "324072       NaN       NaN     3.044804         1.964511         5.021149   \n",
              "\n",
              "        e_J0410_PStotal  e_J0430_PStotal  e_g_PStotal  e_J0515_PStotal  \\\n",
              "0              0.194772         0.245713     0.041893         0.091243   \n",
              "1              1.782604         0.585214     0.124910         0.304120   \n",
              "2             24.218925         2.501554     0.662034         0.650283   \n",
              "3              0.835895         0.634541     0.132246         0.293990   \n",
              "4              0.658014         0.204889     0.070558         0.167561   \n",
              "...                 ...              ...          ...              ...   \n",
              "324068         0.459246         0.648415     0.106416         0.284852   \n",
              "324069         0.390139         0.248238     0.069870         0.143726   \n",
              "324070         1.336982         1.126299     0.116354         0.181017   \n",
              "324071         0.959220              NaN     0.318630         0.995016   \n",
              "324072         2.632960              NaN     0.938834         1.200194   \n",
              "\n",
              "        e_r_PStotal  e_J0660_PStotal  e_i_PStotal  e_J0861_PStotal  \\\n",
              "0          0.025094         0.029657     0.023942         0.055467   \n",
              "1          0.064142         0.059612     0.048313         0.102840   \n",
              "2          0.137526         0.152992     0.092161         0.250096   \n",
              "3          0.064867         0.061165     0.047712         0.101811   \n",
              "4          0.042762         0.063853     0.035506         0.072106   \n",
              "...             ...              ...          ...              ...   \n",
              "324068     0.066846         0.064942     0.065221         0.119365   \n",
              "324069     0.037100         0.040685     0.031847         0.057521   \n",
              "324070     0.036185         0.028266     0.018727         0.026390   \n",
              "324071     0.114878         0.110119     0.081381         0.182333   \n",
              "324072     0.398826         0.737208     3.347102         0.586793   \n",
              "\n",
              "        e_z_PStotal  e_W1_MAG  e_W2_MAG  \n",
              "0          0.036479  0.033687  0.083541  \n",
              "1          0.068152  0.025455  0.062376  \n",
              "2          0.123786  0.019780  0.081629  \n",
              "3          0.062711  0.027340  0.058215  \n",
              "4          0.049442  0.020226  0.054294  \n",
              "...             ...       ...       ...  \n",
              "324068     0.117191       NaN       NaN  \n",
              "324069     0.044997  0.012762  0.044740  \n",
              "324070     0.021848  0.009996  0.021091  \n",
              "324071     0.112433  0.054559  0.129773  \n",
              "324072     0.353271       NaN       NaN  \n",
              "\n",
              "[324073 rows x 16 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.iloc[:, 2:4]\n",
        "a = [34, 35] + list(range(5, 28, 2)) + [30, 31]\n",
        "b = [36, 37] + list(range(6, 29, 2)) + [32, 33]\n",
        "df.iloc[:, b]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AGz22PvSUjKL"
      },
      "outputs": [],
      "source": [
        "set_size = (np.round(np.array([0.5, 0.25, 0.25])*df.shape[0]) + np.array([1, 0, 0])).astype(int).tolist()\n",
        "a = [34, 35] + list(range(5, 28, 2)) + [30, 31]\n",
        "b = [36, 37] + list(range(6, 29, 2)) + [32, 33]\n",
        "\n",
        "f = df.iloc[:, a]\n",
        "e_f = df.iloc[:, b]\n",
        "extra = df.iloc[:, 2:4]\n",
        "\n",
        "z = df.iloc[:, 38]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HUmniuEKUjKM"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import lightning as L\n",
        "\n",
        "from modules import RegressionModule as Reg\n",
        "from blocks import LinearBlock, Conv1dBlock, Conv2dBlock\n",
        "from data import FF_Dataset, Custom_DataModule, CNN1D_Dataset, CNN2D_Dataset\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import MaxPool1d, AvgPool1d\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "from multi import Slicer\n",
        "\n",
        "from math import floor\n",
        "\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "I7QCD5oCUjKM"
      },
      "outputs": [],
      "source": [
        "dm = {}\n",
        "m = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2L4YWgh7UjKN"
      },
      "source": [
        "# FF with filters and no errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HU0h2Kf4UjKO",
        "outputId": "40ea1758-d40a-492c-a781-db4f8a4a9485"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'dm' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mff_filters\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mdm\u001b[49m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m Custom_DataModule(xez \u001b[38;5;241m=\u001b[39m (f, \u001b[38;5;28;01mNone\u001b[39;00m, z), extra\u001b[38;5;241m=\u001b[39mextra,\n\u001b[1;32m      4\u001b[0m                        dataset_class\u001b[38;5;241m=\u001b[39mFF_Dataset,\n\u001b[1;32m      5\u001b[0m                        norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m                        split_size_or_sections\u001b[38;5;241m=\u001b[39mset_size,\n\u001b[1;32m      7\u001b[0m                        batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m)\n\u001b[1;32m      9\u001b[0m l1 \u001b[38;5;241m=\u001b[39m LinearBlock(in_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m18\u001b[39m, out_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m,\n\u001b[1;32m     10\u001b[0m                  norm_layer\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mBatchNorm1d, norm_layer_args\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_features\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m12\u001b[39m},\n\u001b[1;32m     11\u001b[0m                  activation_function\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mReLU)\n\u001b[1;32m     13\u001b[0m l2 \u001b[38;5;241m=\u001b[39m LinearBlock(in_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m, out_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m,\n\u001b[1;32m     14\u001b[0m                  norm_layer\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mBatchNorm1d, norm_layer_args\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_features\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m12\u001b[39m},\n\u001b[1;32m     15\u001b[0m                  activation_function\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mReLU)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dm' is not defined"
          ]
        }
      ],
      "source": [
        "str = 'ff_filters'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (f, None, z), extra=extra,\n",
        "                       dataset_class=FF_Dataset,\n",
        "                       norm=True,\n",
        "                       split_size_or_sections=set_size,\n",
        "                       batch_size=2000, num_workers=7)\n",
        "\n",
        "l1 = LinearBlock(in_features=18, out_features=12,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 12},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=12, out_features=12,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 12},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=12, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=2,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GPFYFJjUjKQ"
      },
      "source": [
        "# FF with filters and errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqRRkyg1UjKQ",
        "outputId": "9909348e-e9f0-4269-e95a-756b8e1847e0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "2024-05-19 17:20:15.721040: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-05-19 17:20:15.759343: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-05-19 17:20:16.741041: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 1.6 K \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "1.6 K     Trainable params\n",
            "0         Non-trainable params\n",
            "1.6 K     Total params\n",
            "0.006     Total estimated model params size (MB)\n",
            "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str = 'ff_filters_errors'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (f, e_f, z), extra=extra,\n",
        "                       dataset_class=FF_Dataset,\n",
        "                       norm=True,\n",
        "                       split_size_or_sections=set_size,\n",
        "                       batch_size=2000, num_workers=7)\n",
        "\n",
        "l1 = LinearBlock(in_features=34, out_features=24,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 24},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=24, out_features=24,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 24},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=24, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=2,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yxGFV4fUjKU"
      },
      "source": [
        "# CNN1D_no with filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6MzCRSxUjKU",
        "outputId": "4027079e-8396-4000-bd12-61541f94aa4c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 53.9 K\n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "53.9 K    Trainable params\n",
            "0         Non-trainable params\n",
            "53.9 K    Total params\n",
            "0.215     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 53.9 K\n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "53.9 K    Trainable params\n",
            "0         Non-trainable params\n",
            "53.9 K    Total params\n",
            "0.215     Total estimated model params size (MB)\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str = 'cnn1d_no_filters'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (f, e_f, z), extra=extra,\n",
        "                       dataset_class=CNN1D_Dataset,\n",
        "                       version='no', norm=True,\n",
        "                       set_size=set_size,\n",
        "                       batch_size=2000, num_workers=7)\n",
        "\n",
        "c1 = Conv1dBlock(in_channels=1, out_channels=32,\n",
        "                 kernel_size=3,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 32},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "c2 = Conv1dBlock(in_channels=32, out_channels=64,\n",
        "                 kernel_size=2,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 64},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "flatten = nn.Flatten()\n",
        "\n",
        "l1 = LinearBlock(in_features=192, out_features=144,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 144},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=144, out_features=144,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 144},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=144, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(c1, c2, flatten,\n",
        "                           l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=250,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<module 'multi' from '/home/lucas-battisti/Área de Trabalho/python-projects/Acnodnem-Ailiram/multi.py'>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import importlib\n",
        "import multi\n",
        "importlib.reload(multi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 1])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str = 'cnn1d_no_filters'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (f, e_f, z), extra=extra,\n",
        "                       dataset_class=CNN1D_Dataset,\n",
        "                       version='no', norm=True,\n",
        "                       split_size_or_sections=set_size,\n",
        "                       batch_size=2000, num_workers=7)\n",
        "\n",
        "sl = multi.Slicer(2, dim = 2)\n",
        "\n",
        "sl_ = sl(dm['cnn1d_no_filters'].train[1:3][0])\n",
        "\n",
        "\n",
        "c1 = Conv1dBlock(in_channels=1, out_channels=32,\n",
        "                 kernel_size=3,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 32},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "c2 = Conv1dBlock(in_channels=32, out_channels=64,\n",
        "                 kernel_size=2,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 64},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "l1 = LinearBlock(in_features=194, out_features=144,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 144},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=144, out_features=144,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 144},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=144, out_features=1)\n",
        "\n",
        "\n",
        "\n",
        "multimodel1 = multi.MultiModule(c1, nn.Identity())\n",
        "multimodel2 = multi.MultiModule(c2, nn.Identity())\n",
        "\n",
        "multimodel1_ = multimodel1(sl_)\n",
        "multimodel2_ = multimodel2(multimodel1_)\n",
        "\n",
        "fl = multi.Joiner_Flatten()\n",
        "\n",
        "fl_ = fl(multimodel2_)\n",
        "\n",
        "sequential = multi.MultiInputSequential(sl, multimodel1, multimodel2, fl, l1, l2, l3)\n",
        "\n",
        "sequential(dm['cnn1d_no_filters'].train[1:3][0]).size()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6XRrCBIUjKU"
      },
      "source": [
        "# CNN1D_no with diffs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZEysR5sUjKV",
        "outputId": "0f652dfe-f493-42d1-ba19-886893570a0c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 44.7 K\n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "44.7 K    Trainable params\n",
            "0         Non-trainable params\n",
            "44.7 K    Total params\n",
            "0.179     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 44.7 K\n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "44.7 K    Trainable params\n",
            "0         Non-trainable params\n",
            "44.7 K    Total params\n",
            "0.179     Total estimated model params size (MB)\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str = 'cnn1d_no_diffs'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (d, e_d, z),\n",
        "                       dataset_class=CNN1D_Dataset,\n",
        "                       version='no', norm=True,\n",
        "                       set_size=set_size,\n",
        "                       batch_size=200, num_workers=1)\n",
        "\n",
        "c1 = Conv1dBlock(in_channels=1, out_channels=32,\n",
        "                 kernel_size=3,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 32},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "c2 = Conv1dBlock(in_channels=32, out_channels=64,\n",
        "                 kernel_size=2,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 64},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "flatten = nn.Flatten()\n",
        "\n",
        "l1 = LinearBlock(in_features=128, out_features=144,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 144},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=144, out_features=144,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 144},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=144, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(c1, c2, flatten,\n",
        "                           l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=250,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfamPT7-UjKV"
      },
      "source": [
        "# CNN1D_with with filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSi-_JD9UjKW",
        "outputId": "5364453e-118a-4b54-dbf1-816a22a71f93"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 270 K \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "270 K     Trainable params\n",
            "0         Non-trainable params\n",
            "270 K     Total params\n",
            "1.081     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 270 K \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "270 K     Trainable params\n",
            "0         Non-trainable params\n",
            "270 K     Total params\n",
            "1.081     Total estimated model params size (MB)\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str = 'cnn1d_with_filters'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (f, e_f, z),\n",
        "                       dataset_class=CNN1D_Dataset,\n",
        "                       version='with', norm=True,\n",
        "                       set_size=set_size,\n",
        "                       batch_size=200, num_workers=1)\n",
        "\n",
        "c1 = Conv1dBlock(in_channels=1, out_channels=32,\n",
        "                 kernel_size=3,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 32},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "c2 = Conv1dBlock(in_channels=32, out_channels=64,\n",
        "                 kernel_size=2,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 64},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "flatten = nn.Flatten()\n",
        "\n",
        "l1 = LinearBlock(in_features=448, out_features=336,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 336},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=336, out_features=336,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 336},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=336, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(c1, c2, flatten,\n",
        "                           l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=250,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYlhEzakUjKW"
      },
      "source": [
        "# CNN1D_with with diffs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ovm2BQF-UjKW",
        "outputId": "ad5bba48-3eb5-4c5d-e9e9-ebaca93e48a9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 248 K \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "248 K     Trainable params\n",
            "0         Non-trainable params\n",
            "248 K     Total params\n",
            "0.995     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 248 K \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "248 K     Trainable params\n",
            "0         Non-trainable params\n",
            "248 K     Total params\n",
            "0.995     Total estimated model params size (MB)\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str = 'cnn1d_with_diffs'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (d, e_d, z),\n",
        "                       dataset_class=CNN1D_Dataset,\n",
        "                       version='with', norm=True,\n",
        "                       set_size=set_size,\n",
        "                       batch_size=200, num_workers=1)\n",
        "\n",
        "c1 = Conv1dBlock(in_channels=1, out_channels=32,\n",
        "                 kernel_size=3,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 32},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "c2 = Conv1dBlock(in_channels=32, out_channels=64,\n",
        "                 kernel_size=2,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 64},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "flatten = nn.Flatten()\n",
        "\n",
        "l1 = LinearBlock(in_features=384, out_features=336,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 336},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=336, out_features=336,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 336},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=336, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(c1, c2, flatten,\n",
        "                           l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,max_epochs=250\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=250,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suaAYcQfUjKX"
      },
      "source": [
        "# CNN1D_stack with filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2L7x7jfJUjKX",
        "outputId": "635b3bb3-1d2b-4e2c-e3d1-b6c8942a1b5f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 54.0 K\n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "54.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "54.0 K    Total params\n",
            "0.216     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 54.0 K\n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "54.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "54.0 K    Total params\n",
            "0.216     Total estimated model params size (MB)\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str = 'cnn1d_stack_filters'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (f, e_f, z),\n",
        "                       dataset_class=CNN1D_Dataset,\n",
        "                       version='stack', norm=True,\n",
        "                       set_size=set_size,\n",
        "                       batch_size=200, num_workers=1)\n",
        "\n",
        "c1 = Conv1dBlock(in_channels=2, out_channels=32,\n",
        "                 kernel_size=3,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 32},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "c2 = Conv1dBlock(in_channels=32, out_channels=64,\n",
        "                 kernel_size=2,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 64},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "flatten = nn.Flatten()\n",
        "\n",
        "l1 = LinearBlock(in_features=192, out_features=144,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 144},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=144, out_features=144,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 144},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=144, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(c1, c2, flatten,\n",
        "                           l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=250,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-yDhG1SUjKY"
      },
      "source": [
        "# CNN1D_stack with diffs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AilGuS8CUjKY",
        "outputId": "f54d66ae-7697-4196-bb5a-932e1300bee3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 46.9 K\n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "46.9 K    Trainable params\n",
            "0         Non-trainable params\n",
            "46.9 K    Total params\n",
            "0.187     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 46.9 K\n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "46.9 K    Trainable params\n",
            "0         Non-trainable params\n",
            "46.9 K    Total params\n",
            "0.187     Total estimated model params size (MB)\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str = 'cnn1d_stack_diffs'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (d, e_d, z),\n",
        "                       dataset_class=CNN1D_Dataset,\n",
        "                       version='stack', norm=True,\n",
        "                       set_size=set_size,\n",
        "                       batch_size=200, num_workers=1)\n",
        "\n",
        "c1 = Conv1dBlock(in_channels=2, out_channels=32,\n",
        "                 kernel_size=4,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 32},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "c2 = Conv1dBlock(in_channels=32, out_channels=64,\n",
        "                 kernel_size=3,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 64},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "flatten = nn.Flatten()\n",
        "\n",
        "l1 = LinearBlock(in_features=128, out_features=144,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 144},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=144, out_features=144,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 144},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=144, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(c1, c2, flatten,\n",
        "                           l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=250,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPGIRVW-UjKY"
      },
      "source": [
        "# CNN2D with filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLgl75pxUjKY",
        "outputId": "6078749c-5841-4e2e-a55a-5f6d84b2e325"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: False, used: False\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: \n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 214 K \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "214 K     Trainable params\n",
            "0         Non-trainable params\n",
            "214 K     Total params\n",
            "0.859     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 214 K \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "214 K     Trainable params\n",
            "0         Non-trainable params\n",
            "214 K     Total params\n",
            "0.859     Total estimated model params size (MB)\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=175` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=175` reached.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str = 'cnn2d_filters'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (f, e_f, z),\n",
        "                       dataset_class=CNN2D_Dataset,\n",
        "                       K=20, t_inf=10, t_sup=10, norm=True,\n",
        "                       set_size=set_size,\n",
        "                       batch_size=200, num_workers=1)\n",
        "\n",
        "c1 = Conv2dBlock(in_channels=1, out_channels=32,\n",
        "                 kernel_size=4,\n",
        "                 norm_layer=nn.BatchNorm2d, norm_layer_args={'num_features': 32},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=nn.MaxPool2d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "c2 = Conv2dBlock(in_channels=32, out_channels=64,\n",
        "                 kernel_size=3,\n",
        "                 norm_layer=nn.BatchNorm2d, norm_layer_args={'num_features': 64},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=nn.MaxPool2d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "flatten = nn.Flatten()\n",
        "\n",
        "l1 = LinearBlock(in_features=384, out_features=288,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 288},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=288, out_features=288,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 288},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=288, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(c1, c2, flatten,\n",
        "                           l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=175,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OocjQ0b-UjKZ"
      },
      "source": [
        "# CNN2D with diffs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEFIEFUqUjKZ",
        "outputId": "37df4bf2-474f-418a-af15-d4ed1715a54e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: False, used: False\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: \n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 159 K \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "159 K     Trainable params\n",
            "0         Non-trainable params\n",
            "159 K     Total params\n",
            "0.639     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 159 K \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "159 K     Trainable params\n",
            "0         Non-trainable params\n",
            "159 K     Total params\n",
            "0.639     Total estimated model params size (MB)\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=250` reached.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str = 'cnn2d_diffs'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (d, e_d, z),\n",
        "                       dataset_class=CNN2D_Dataset,\n",
        "                       K=20, t_inf=10, t_sup=10, norm=True,\n",
        "                       set_size=set_size,\n",
        "                       batch_size=200, num_workers=1)\n",
        "\n",
        "c1 = Conv2dBlock(in_channels=1, out_channels=32,\n",
        "                 kernel_size=5,\n",
        "                 norm_layer=nn.BatchNorm2d, norm_layer_args={'num_features': 32},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=nn.MaxPool2d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "c2 = Conv2dBlock(in_channels=32, out_channels=64,\n",
        "                 kernel_size=3,\n",
        "                 norm_layer=nn.BatchNorm2d, norm_layer_args={'num_features': 64},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=nn.MaxPool2d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "flatten = nn.Flatten()\n",
        "\n",
        "l1 = LinearBlock(in_features=192, out_features=288,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 288},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=288, out_features=288,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 288},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=288, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(c1, c2, flatten,\n",
        "                           l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=250,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eA-6znM63seE",
        "outputId": "c2a43897-c7a7-4bba-9fd2-53e9d8f3f345"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: ff_filters/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_std/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_std/events.out.tfevents.1712597390.605934e206d9.368.26 (deflated 10%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_mean/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_mean/events.out.tfevents.1712597079.605934e206d9.368.17 (deflated 74%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_size/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_size/events.out.tfevents.1712597390.605934e206d9.368.27 (deflated 10%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_median/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_median/events.out.tfevents.1712597077.605934e206d9.368.5 (deflated 76%)\n",
            "  adding: ff_filters/lightning_logs/version_0/losses_validation_loss/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/losses_validation_loss/events.out.tfevents.1712597077.605934e206d9.368.2 (deflated 63%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_min/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_min/events.out.tfevents.1712597390.605934e206d9.368.20 (deflated 10%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_min/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_min/events.out.tfevents.1712597079.605934e206d9.368.12 (deflated 76%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_q3/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_q3/events.out.tfevents.1712597077.605934e206d9.368.6 (deflated 76%)\n",
            "  adding: ff_filters/lightning_logs/version_0/losses_training_loss/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/losses_training_loss/events.out.tfevents.1712597079.605934e206d9.368.11 (deflated 63%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_std/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_std/events.out.tfevents.1712597079.605934e206d9.368.18 (deflated 74%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_max/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_max/events.out.tfevents.1712597390.605934e206d9.368.24 (deflated 10%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_q1/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_q1/events.out.tfevents.1712597390.605934e206d9.368.21 (deflated 10%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_max/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_max/events.out.tfevents.1712597077.605934e206d9.368.7 (deflated 76%)\n",
            "  adding: ff_filters/lightning_logs/version_0/events.out.tfevents.1712597077.605934e206d9.368.1 (deflated 5%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_mean/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_mean/events.out.tfevents.1712597390.605934e206d9.368.25 (deflated 10%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_q1/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_q1/events.out.tfevents.1712597077.605934e206d9.368.4 (deflated 76%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_q3/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_q3/events.out.tfevents.1712597390.605934e206d9.368.23 (deflated 10%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_mean/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_mean/events.out.tfevents.1712597077.605934e206d9.368.8 (deflated 76%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_q3/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_q3/events.out.tfevents.1712597079.605934e206d9.368.15 (deflated 74%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_std/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_std/events.out.tfevents.1712597077.605934e206d9.368.9 (deflated 76%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_q1/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_q1/events.out.tfevents.1712597079.605934e206d9.368.13 (deflated 74%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_size/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_size/events.out.tfevents.1712597079.605934e206d9.368.19 (deflated 79%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_median/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_median/events.out.tfevents.1712597390.605934e206d9.368.22 (deflated 10%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_max/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_max/events.out.tfevents.1712597079.605934e206d9.368.16 (deflated 74%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_median/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_median/events.out.tfevents.1712597079.605934e206d9.368.14 (deflated 74%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_min/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_min/events.out.tfevents.1712597077.605934e206d9.368.3 (deflated 76%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_size/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_size/events.out.tfevents.1712597077.605934e206d9.368.10 (deflated 81%)\n",
            "  adding: cnn2d_filters/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_std/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_std/events.out.tfevents.1712602014.605934e206d9.368.110 (deflated 9%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_mean/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_mean/events.out.tfevents.1712600262.605934e206d9.368.101 (deflated 72%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_size/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_size/events.out.tfevents.1712602014.605934e206d9.368.111 (deflated 9%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_median/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_median/events.out.tfevents.1712600251.605934e206d9.368.89 (deflated 74%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/losses_validation_loss/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/losses_validation_loss/events.out.tfevents.1712600251.605934e206d9.368.86 (deflated 61%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_min/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_min/events.out.tfevents.1712602014.605934e206d9.368.104 (deflated 9%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_min/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_min/events.out.tfevents.1712600262.605934e206d9.368.96 (deflated 74%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_q3/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_q3/events.out.tfevents.1712600251.605934e206d9.368.90 (deflated 74%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/losses_training_loss/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/losses_training_loss/events.out.tfevents.1712600262.605934e206d9.368.95 (deflated 60%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_std/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_std/events.out.tfevents.1712600262.605934e206d9.368.102 (deflated 72%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_max/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_max/events.out.tfevents.1712602014.605934e206d9.368.108 (deflated 9%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_q1/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_q1/events.out.tfevents.1712602014.605934e206d9.368.105 (deflated 9%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/events.out.tfevents.1712600251.605934e206d9.368.85 (deflated 4%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_max/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_max/events.out.tfevents.1712600251.605934e206d9.368.91 (deflated 74%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_mean/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_mean/events.out.tfevents.1712602014.605934e206d9.368.109 (deflated 9%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_q1/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_q1/events.out.tfevents.1712600251.605934e206d9.368.88 (deflated 74%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_q3/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_q3/events.out.tfevents.1712602014.605934e206d9.368.107 (deflated 9%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_mean/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_mean/events.out.tfevents.1712600251.605934e206d9.368.92 (deflated 74%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_q3/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_q3/events.out.tfevents.1712600262.605934e206d9.368.99 (deflated 72%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_std/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_std/events.out.tfevents.1712600251.605934e206d9.368.93 (deflated 74%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_q1/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_q1/events.out.tfevents.1712600262.605934e206d9.368.97 (deflated 72%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_size/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_size/events.out.tfevents.1712600262.605934e206d9.368.103 (deflated 78%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_median/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_median/events.out.tfevents.1712602014.605934e206d9.368.106 (deflated 9%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_max/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_max/events.out.tfevents.1712600262.605934e206d9.368.100 (deflated 72%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_median/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_median/events.out.tfevents.1712600262.605934e206d9.368.98 (deflated 72%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_min/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_min/events.out.tfevents.1712600251.605934e206d9.368.87 (deflated 74%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_size/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_size/events.out.tfevents.1712600251.605934e206d9.368.94 (deflated 79%)\n",
            "  adding: cnn2d_diffs/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_std/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_std/events.out.tfevents.1712600249.605934e206d9.368.82 (deflated 10%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_mean/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_mean/events.out.tfevents.1712597858.605934e206d9.368.73 (deflated 73%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_size/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_size/events.out.tfevents.1712600249.605934e206d9.368.83 (deflated 10%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_median/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_median/events.out.tfevents.1712597849.605934e206d9.368.61 (deflated 75%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/losses_validation_loss/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/losses_validation_loss/events.out.tfevents.1712597849.605934e206d9.368.58 (deflated 61%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_min/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_min/events.out.tfevents.1712600249.605934e206d9.368.76 (deflated 10%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_min/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_min/events.out.tfevents.1712597858.605934e206d9.368.68 (deflated 75%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q3/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q3/events.out.tfevents.1712597849.605934e206d9.368.62 (deflated 75%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/losses_training_loss/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/losses_training_loss/events.out.tfevents.1712597858.605934e206d9.368.67 (deflated 61%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_std/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_std/events.out.tfevents.1712597858.605934e206d9.368.74 (deflated 73%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_max/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_max/events.out.tfevents.1712600249.605934e206d9.368.80 (deflated 10%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_q1/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_q1/events.out.tfevents.1712600249.605934e206d9.368.77 (deflated 10%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_max/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_max/events.out.tfevents.1712597849.605934e206d9.368.63 (deflated 75%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_mean/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_mean/events.out.tfevents.1712600249.605934e206d9.368.81 (deflated 10%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q1/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q1/events.out.tfevents.1712597849.605934e206d9.368.60 (deflated 75%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_q3/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_q3/events.out.tfevents.1712600249.605934e206d9.368.79 (deflated 10%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_mean/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_mean/events.out.tfevents.1712597849.605934e206d9.368.64 (deflated 75%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_q3/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_q3/events.out.tfevents.1712597858.605934e206d9.368.71 (deflated 73%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_std/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_std/events.out.tfevents.1712597849.605934e206d9.368.65 (deflated 75%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_q1/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_q1/events.out.tfevents.1712597858.605934e206d9.368.69 (deflated 73%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_size/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_size/events.out.tfevents.1712597858.605934e206d9.368.75 (deflated 78%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_median/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_median/events.out.tfevents.1712600249.605934e206d9.368.78 (deflated 10%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_max/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_max/events.out.tfevents.1712597858.605934e206d9.368.72 (deflated 73%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/events.out.tfevents.1712597849.605934e206d9.368.57 (deflated 5%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_median/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_median/events.out.tfevents.1712597858.605934e206d9.368.70 (deflated 73%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_min/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_min/events.out.tfevents.1712597849.605934e206d9.368.59 (deflated 75%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_size/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_size/events.out.tfevents.1712597849.605934e206d9.368.66 (deflated 80%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r ff_filters.zip ff_filters\n",
        "#!zip -r ff_filters_errors.zip ff_filters_errors\n",
        "#!zip -r ff_diffs.zip ff_diffs\n",
        "#!zip -r ff_diffs_errors.zip ff_diffs_errors\n",
        "#!zip -r cnn1d_no_filters.zip cnn1d_no_filters\n",
        "#!zip -r cnn1d_no_diffs.zip cnn1d_no_diffs\n",
        "#!zip -r cnn1d_with_filters.zip cnn1d_with_filters\n",
        "#!zip -r cnn1d_with_diffs.zip cnn1d_with_diffs\n",
        "#!zip -r cnn1d_stack_filters.zip cnn1d_stack_filters\n",
        "#!zip -r cnn1d_stack_diffs.zip cnn1d_stack_diffs\n",
        "!zip -r cnn2d_filters.zip cnn2d_filters\n",
        "!zip -r cnn2d_diffs.zip cnn2d_diffs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "4wbuAKbR355x",
        "outputId": "2614302a-fcdb-4351-c27e-528fff89f227"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_061163e7-6b64-481b-87e0-142f9918a915\", \"ff_filters.zip\", 122730)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_772a90be-94de-402b-917e-8fd2874574b1\", \"cnn2d_filters.zip\", 100050)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_14b82663-936d-4967-b774-8aa5bfc456e7\", \"cnn2d_diffs.zip\", 127066)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"ff_filters.zip\")\n",
        "#files.download(\"ff_filters_errors.zip\")\n",
        "#files.download(\"ff_diffs.zip\")\n",
        "#files.download(\"ff_diffs_errors.zip\")\n",
        "#files.download(\"cnn1d_no_filters.zip\")\n",
        "#files.download(\"cnn1d_no_diffs.zip\")\n",
        "#files.download(\"cnn1d_with_filters.zip\")\n",
        "#files.download(\"cnn1d_with_diffs.zip\")\n",
        "#files.download(\"cnn1d_stack_filters.zip\")\n",
        "#files.download(\"cnn1d_stack_diffs.zip\")\n",
        "files.download(\"cnn2d_filters.zip\")\n",
        "files.download(\"cnn2d_diffs.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atlQEfGddz11",
        "outputId": "18a59ad1-b08a-4464-a7d0-fe0b72d27887"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  ff_diffs.zip\n",
            "   creating: ff_diffs/\n",
            "   creating: ff_diffs/lightning_logs/\n",
            "   creating: ff_diffs/lightning_logs/version_0/\n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_median/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_median/events.out.tfevents.1712571718.5987425793bc.2443.70  \n",
            "   creating: ff_diffs/lightning_logs/version_0/losses_training_loss/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/losses_training_loss/events.out.tfevents.1712571718.5987425793bc.2443.67  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_max/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_max/events.out.tfevents.1712571718.5987425793bc.2443.72  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_std/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_std/events.out.tfevents.1712571717.5987425793bc.2443.65  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_min/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_min/events.out.tfevents.1712571718.5987425793bc.2443.68  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_mean/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_mean/events.out.tfevents.1712571717.5987425793bc.2443.64  \n",
            "  inflating: ff_diffs/lightning_logs/version_0/events.out.tfevents.1712571717.5987425793bc.2443.57  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_mean/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_mean/events.out.tfevents.1712571984.5987425793bc.2443.81  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_median/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_median/events.out.tfevents.1712571984.5987425793bc.2443.78  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_std/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_std/events.out.tfevents.1712571718.5987425793bc.2443.74  \n",
            "   creating: ff_diffs/lightning_logs/version_0/losses_validation_loss/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/losses_validation_loss/events.out.tfevents.1712571717.5987425793bc.2443.58  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_median/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_median/events.out.tfevents.1712571717.5987425793bc.2443.61  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_std/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_std/events.out.tfevents.1712571984.5987425793bc.2443.82  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_size/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_size/events.out.tfevents.1712571984.5987425793bc.2443.83  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_mean/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_mean/events.out.tfevents.1712571718.5987425793bc.2443.73  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_size/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_size/events.out.tfevents.1712571718.5987425793bc.2443.75  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_max/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_max/events.out.tfevents.1712571717.5987425793bc.2443.63  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_min/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_min/events.out.tfevents.1712571717.5987425793bc.2443.59  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_q3/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_q3/events.out.tfevents.1712571984.5987425793bc.2443.79  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_q1/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_q1/events.out.tfevents.1712571984.5987425793bc.2443.77  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_size/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_size/events.out.tfevents.1712571717.5987425793bc.2443.66  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_q1/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_q1/events.out.tfevents.1712571718.5987425793bc.2443.69  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q1/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q1/events.out.tfevents.1712571717.5987425793bc.2443.60  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_q3/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_q3/events.out.tfevents.1712571718.5987425793bc.2443.71  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q3/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q3/events.out.tfevents.1712571717.5987425793bc.2443.62  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_min/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_min/events.out.tfevents.1712571984.5987425793bc.2443.76  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_max/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_max/events.out.tfevents.1712571984.5987425793bc.2443.80  \n",
            "Archive:  ff_diffs_errors.zip\n",
            "   creating: ff_diffs_errors/\n",
            "   creating: ff_diffs_errors/lightning_logs/\n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/\n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_median/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_median/events.out.tfevents.1712571986.5987425793bc.2443.98  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/losses_training_loss/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/losses_training_loss/events.out.tfevents.1712571986.5987425793bc.2443.95  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_max/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_max/events.out.tfevents.1712571986.5987425793bc.2443.100  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_std/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_std/events.out.tfevents.1712571985.5987425793bc.2443.93  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_min/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_min/events.out.tfevents.1712571986.5987425793bc.2443.96  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_mean/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_mean/events.out.tfevents.1712571985.5987425793bc.2443.92  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_mean/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_mean/events.out.tfevents.1712572258.5987425793bc.2443.109  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_median/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_median/events.out.tfevents.1712572258.5987425793bc.2443.106  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_std/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_std/events.out.tfevents.1712571986.5987425793bc.2443.102  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/losses_validation_loss/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/losses_validation_loss/events.out.tfevents.1712571985.5987425793bc.2443.86  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_median/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_median/events.out.tfevents.1712571985.5987425793bc.2443.89  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_std/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_std/events.out.tfevents.1712572258.5987425793bc.2443.110  \n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/events.out.tfevents.1712571985.5987425793bc.2443.85  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_size/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_size/events.out.tfevents.1712572258.5987425793bc.2443.111  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_mean/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_mean/events.out.tfevents.1712571986.5987425793bc.2443.101  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_size/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_size/events.out.tfevents.1712571986.5987425793bc.2443.103  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_max/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_max/events.out.tfevents.1712571985.5987425793bc.2443.91  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_min/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_min/events.out.tfevents.1712571985.5987425793bc.2443.87  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_q3/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_q3/events.out.tfevents.1712572258.5987425793bc.2443.107  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_q1/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_q1/events.out.tfevents.1712572258.5987425793bc.2443.105  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_size/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_size/events.out.tfevents.1712571985.5987425793bc.2443.94  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_q1/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_q1/events.out.tfevents.1712571986.5987425793bc.2443.97  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_q1/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_q1/events.out.tfevents.1712571985.5987425793bc.2443.88  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_q3/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_q3/events.out.tfevents.1712571986.5987425793bc.2443.99  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_q3/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_q3/events.out.tfevents.1712571985.5987425793bc.2443.90  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_min/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_min/events.out.tfevents.1712572258.5987425793bc.2443.104  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_max/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_max/events.out.tfevents.1712572258.5987425793bc.2443.108  \n",
            "Archive:  cnn1d_no_filters.zip\n",
            "   creating: cnn1d_no_filters/\n",
            "   creating: cnn1d_no_filters/lightning_logs/\n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/\n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_median/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_median/events.out.tfevents.1712572260.5987425793bc.2443.126  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/losses_training_loss/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/losses_training_loss/events.out.tfevents.1712572260.5987425793bc.2443.123  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_max/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_max/events.out.tfevents.1712572260.5987425793bc.2443.128  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_std/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_std/events.out.tfevents.1712572259.5987425793bc.2443.121  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_min/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_min/events.out.tfevents.1712572260.5987425793bc.2443.124  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_mean/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_mean/events.out.tfevents.1712572258.5987425793bc.2443.120  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_mean/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_mean/events.out.tfevents.1712572585.5987425793bc.2443.137  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_median/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_median/events.out.tfevents.1712572585.5987425793bc.2443.134  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_std/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_std/events.out.tfevents.1712572260.5987425793bc.2443.130  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/losses_validation_loss/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/losses_validation_loss/events.out.tfevents.1712572258.5987425793bc.2443.114  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_median/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_median/events.out.tfevents.1712572258.5987425793bc.2443.117  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_std/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_std/events.out.tfevents.1712572585.5987425793bc.2443.138  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_size/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_size/events.out.tfevents.1712572585.5987425793bc.2443.139  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_mean/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_mean/events.out.tfevents.1712572260.5987425793bc.2443.129  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_size/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_size/events.out.tfevents.1712572260.5987425793bc.2443.131  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_max/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_max/events.out.tfevents.1712572258.5987425793bc.2443.119  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_min/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_min/events.out.tfevents.1712572258.5987425793bc.2443.115  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_q3/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_q3/events.out.tfevents.1712572585.5987425793bc.2443.135  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_q1/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_q1/events.out.tfevents.1712572585.5987425793bc.2443.133  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_size/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_size/events.out.tfevents.1712572259.5987425793bc.2443.122  \n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/events.out.tfevents.1712572258.5987425793bc.2443.113  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_q1/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_q1/events.out.tfevents.1712572260.5987425793bc.2443.125  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_q1/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_q1/events.out.tfevents.1712572258.5987425793bc.2443.116  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_q3/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_q3/events.out.tfevents.1712572260.5987425793bc.2443.127  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_q3/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_q3/events.out.tfevents.1712572258.5987425793bc.2443.118  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_min/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_min/events.out.tfevents.1712572585.5987425793bc.2443.132  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_max/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_max/events.out.tfevents.1712572585.5987425793bc.2443.136  \n",
            "Archive:  cnn1d_no_diffs.zip\n",
            "   creating: cnn1d_no_diffs/\n",
            "   creating: cnn1d_no_diffs/lightning_logs/\n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/\n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_median/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_median/events.out.tfevents.1712572587.5987425793bc.2443.154  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/losses_training_loss/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/losses_training_loss/events.out.tfevents.1712572587.5987425793bc.2443.151  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_max/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_max/events.out.tfevents.1712572587.5987425793bc.2443.156  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_std/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_std/events.out.tfevents.1712572586.5987425793bc.2443.149  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_min/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_min/events.out.tfevents.1712572587.5987425793bc.2443.152  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_mean/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_mean/events.out.tfevents.1712572586.5987425793bc.2443.148  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_mean/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_mean/events.out.tfevents.1712572917.5987425793bc.2443.165  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_median/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_median/events.out.tfevents.1712572917.5987425793bc.2443.162  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_std/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_std/events.out.tfevents.1712572587.5987425793bc.2443.158  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/losses_validation_loss/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/losses_validation_loss/events.out.tfevents.1712572586.5987425793bc.2443.142  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_median/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_median/events.out.tfevents.1712572586.5987425793bc.2443.145  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_std/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_std/events.out.tfevents.1712572917.5987425793bc.2443.166  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_size/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_size/events.out.tfevents.1712572917.5987425793bc.2443.167  \n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/events.out.tfevents.1712572586.5987425793bc.2443.141  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_mean/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_mean/events.out.tfevents.1712572587.5987425793bc.2443.157  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_size/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_size/events.out.tfevents.1712572587.5987425793bc.2443.159  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_max/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_max/events.out.tfevents.1712572586.5987425793bc.2443.147  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_min/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_min/events.out.tfevents.1712572586.5987425793bc.2443.143  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_q3/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_q3/events.out.tfevents.1712572917.5987425793bc.2443.163  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_q1/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_q1/events.out.tfevents.1712572917.5987425793bc.2443.161  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_size/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_size/events.out.tfevents.1712572586.5987425793bc.2443.150  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_q1/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_q1/events.out.tfevents.1712572587.5987425793bc.2443.153  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q1/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q1/events.out.tfevents.1712572586.5987425793bc.2443.144  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_q3/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_q3/events.out.tfevents.1712572587.5987425793bc.2443.155  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q3/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q3/events.out.tfevents.1712572586.5987425793bc.2443.146  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_min/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_min/events.out.tfevents.1712572917.5987425793bc.2443.160  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_max/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_max/events.out.tfevents.1712572917.5987425793bc.2443.164  \n",
            "Archive:  cnn1d_with_filters.zip\n",
            "   creating: cnn1d_with_filters/\n",
            "   creating: cnn1d_with_filters/lightning_logs/\n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/\n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_median/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_median/events.out.tfevents.1712572919.5987425793bc.2443.182  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/losses_training_loss/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/losses_training_loss/events.out.tfevents.1712572919.5987425793bc.2443.179  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_max/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_max/events.out.tfevents.1712572919.5987425793bc.2443.184  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_std/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_std/events.out.tfevents.1712572917.5987425793bc.2443.177  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_min/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_min/events.out.tfevents.1712572919.5987425793bc.2443.180  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_mean/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_mean/events.out.tfevents.1712572917.5987425793bc.2443.176  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_mean/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_mean/events.out.tfevents.1712573265.5987425793bc.2443.193  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_median/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_median/events.out.tfevents.1712573265.5987425793bc.2443.190  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_std/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_std/events.out.tfevents.1712572919.5987425793bc.2443.186  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/losses_validation_loss/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/losses_validation_loss/events.out.tfevents.1712572917.5987425793bc.2443.170  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_median/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_median/events.out.tfevents.1712572917.5987425793bc.2443.173  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_std/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_std/events.out.tfevents.1712573265.5987425793bc.2443.194  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_size/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_size/events.out.tfevents.1712573265.5987425793bc.2443.195  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_mean/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_mean/events.out.tfevents.1712572919.5987425793bc.2443.185  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_size/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_size/events.out.tfevents.1712572919.5987425793bc.2443.187  \n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/events.out.tfevents.1712572917.5987425793bc.2443.169  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_max/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_max/events.out.tfevents.1712572917.5987425793bc.2443.175  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_min/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_min/events.out.tfevents.1712572917.5987425793bc.2443.171  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_q3/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_q3/events.out.tfevents.1712573265.5987425793bc.2443.191  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_q1/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_q1/events.out.tfevents.1712573265.5987425793bc.2443.189  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_size/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_size/events.out.tfevents.1712572917.5987425793bc.2443.178  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_q1/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_q1/events.out.tfevents.1712572919.5987425793bc.2443.181  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_q1/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_q1/events.out.tfevents.1712572917.5987425793bc.2443.172  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_q3/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_q3/events.out.tfevents.1712572919.5987425793bc.2443.183  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_q3/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_q3/events.out.tfevents.1712572917.5987425793bc.2443.174  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_min/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_min/events.out.tfevents.1712573265.5987425793bc.2443.188  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_max/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_max/events.out.tfevents.1712573265.5987425793bc.2443.192  \n",
            "Archive:  cnn1d_with_diffs.zip\n",
            "   creating: cnn1d_with_diffs/\n",
            "   creating: cnn1d_with_diffs/lightning_logs/\n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/events.out.tfevents.1712573266.5987425793bc.2443.197  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_median/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_median/events.out.tfevents.1712573267.5987425793bc.2443.210  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/losses_training_loss/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/losses_training_loss/events.out.tfevents.1712573267.5987425793bc.2443.207  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_max/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_max/events.out.tfevents.1712573267.5987425793bc.2443.212  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_std/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_std/events.out.tfevents.1712573266.5987425793bc.2443.205  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_min/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_min/events.out.tfevents.1712573267.5987425793bc.2443.208  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_mean/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_mean/events.out.tfevents.1712573266.5987425793bc.2443.204  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_mean/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_mean/events.out.tfevents.1712573615.5987425793bc.2443.221  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_median/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_median/events.out.tfevents.1712573615.5987425793bc.2443.218  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_std/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_std/events.out.tfevents.1712573267.5987425793bc.2443.214  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/losses_validation_loss/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/losses_validation_loss/events.out.tfevents.1712573266.5987425793bc.2443.198  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_median/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_median/events.out.tfevents.1712573266.5987425793bc.2443.201  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_std/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_std/events.out.tfevents.1712573615.5987425793bc.2443.222  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_size/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_size/events.out.tfevents.1712573615.5987425793bc.2443.223  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_mean/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_mean/events.out.tfevents.1712573267.5987425793bc.2443.213  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_size/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_size/events.out.tfevents.1712573267.5987425793bc.2443.215  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_max/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_max/events.out.tfevents.1712573266.5987425793bc.2443.203  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_min/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_min/events.out.tfevents.1712573266.5987425793bc.2443.199  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_q3/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_q3/events.out.tfevents.1712573615.5987425793bc.2443.219  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_q1/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_q1/events.out.tfevents.1712573615.5987425793bc.2443.217  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_size/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_size/events.out.tfevents.1712573266.5987425793bc.2443.206  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_q1/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_q1/events.out.tfevents.1712573267.5987425793bc.2443.209  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q1/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q1/events.out.tfevents.1712573266.5987425793bc.2443.200  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_q3/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_q3/events.out.tfevents.1712573267.5987425793bc.2443.211  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q3/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q3/events.out.tfevents.1712573266.5987425793bc.2443.202  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_min/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_min/events.out.tfevents.1712573615.5987425793bc.2443.216  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_max/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_max/events.out.tfevents.1712573615.5987425793bc.2443.220  \n",
            "Archive:  cnn1d_stack_filters.zip\n",
            "   creating: cnn1d_stack_filters/\n",
            "   creating: cnn1d_stack_filters/lightning_logs/\n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/\n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_median/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_median/events.out.tfevents.1712573617.5987425793bc.2443.238  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/losses_training_loss/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/losses_training_loss/events.out.tfevents.1712573617.5987425793bc.2443.235  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_max/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_max/events.out.tfevents.1712573617.5987425793bc.2443.240  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_std/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_std/events.out.tfevents.1712573616.5987425793bc.2443.233  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_min/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_min/events.out.tfevents.1712573617.5987425793bc.2443.236  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_mean/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_mean/events.out.tfevents.1712573616.5987425793bc.2443.232  \n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/events.out.tfevents.1712573616.5987425793bc.2443.225  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_mean/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_mean/events.out.tfevents.1712573967.5987425793bc.2443.249  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_median/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_median/events.out.tfevents.1712573967.5987425793bc.2443.246  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_std/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_std/events.out.tfevents.1712573617.5987425793bc.2443.242  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/losses_validation_loss/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/losses_validation_loss/events.out.tfevents.1712573616.5987425793bc.2443.226  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_median/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_median/events.out.tfevents.1712573616.5987425793bc.2443.229  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_std/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_std/events.out.tfevents.1712573967.5987425793bc.2443.250  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_size/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_size/events.out.tfevents.1712573967.5987425793bc.2443.251  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_mean/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_mean/events.out.tfevents.1712573617.5987425793bc.2443.241  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_size/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_size/events.out.tfevents.1712573617.5987425793bc.2443.243  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_max/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_max/events.out.tfevents.1712573616.5987425793bc.2443.231  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_min/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_min/events.out.tfevents.1712573616.5987425793bc.2443.227  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_q3/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_q3/events.out.tfevents.1712573967.5987425793bc.2443.247  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_q1/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_q1/events.out.tfevents.1712573967.5987425793bc.2443.245  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_size/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_size/events.out.tfevents.1712573616.5987425793bc.2443.234  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_q1/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_q1/events.out.tfevents.1712573617.5987425793bc.2443.237  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_q1/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_q1/events.out.tfevents.1712573616.5987425793bc.2443.228  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_q3/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_q3/events.out.tfevents.1712573617.5987425793bc.2443.239  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_q3/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_q3/events.out.tfevents.1712573616.5987425793bc.2443.230  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_min/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_min/events.out.tfevents.1712573967.5987425793bc.2443.244  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_max/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_max/events.out.tfevents.1712573967.5987425793bc.2443.248  \n",
            "Archive:  cnn1d_stack_diffs.zip\n",
            "   creating: cnn1d_stack_diffs/\n",
            "   creating: cnn1d_stack_diffs/lightning_logs/\n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/\n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_median/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_median/events.out.tfevents.1712573969.5987425793bc.2443.266  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/losses_training_loss/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/losses_training_loss/events.out.tfevents.1712573969.5987425793bc.2443.263  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_max/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_max/events.out.tfevents.1712573969.5987425793bc.2443.268  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_std/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_std/events.out.tfevents.1712573968.5987425793bc.2443.261  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_min/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_min/events.out.tfevents.1712573969.5987425793bc.2443.264  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_mean/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_mean/events.out.tfevents.1712573968.5987425793bc.2443.260  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_mean/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_mean/events.out.tfevents.1712574317.5987425793bc.2443.277  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_median/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_median/events.out.tfevents.1712574317.5987425793bc.2443.274  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_std/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_std/events.out.tfevents.1712573969.5987425793bc.2443.270  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/losses_validation_loss/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/losses_validation_loss/events.out.tfevents.1712573968.5987425793bc.2443.254  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_median/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_median/events.out.tfevents.1712573968.5987425793bc.2443.257  \n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/events.out.tfevents.1712573968.5987425793bc.2443.253  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_std/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_std/events.out.tfevents.1712574317.5987425793bc.2443.278  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_size/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_size/events.out.tfevents.1712574317.5987425793bc.2443.279  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_mean/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_mean/events.out.tfevents.1712573969.5987425793bc.2443.269  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_size/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_size/events.out.tfevents.1712573969.5987425793bc.2443.271  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_max/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_max/events.out.tfevents.1712573968.5987425793bc.2443.259  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_min/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_min/events.out.tfevents.1712573968.5987425793bc.2443.255  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_q3/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_q3/events.out.tfevents.1712574317.5987425793bc.2443.275  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_q1/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_q1/events.out.tfevents.1712574317.5987425793bc.2443.273  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_size/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_size/events.out.tfevents.1712573968.5987425793bc.2443.262  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_q1/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_q1/events.out.tfevents.1712573969.5987425793bc.2443.265  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q1/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q1/events.out.tfevents.1712573968.5987425793bc.2443.256  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_q3/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_q3/events.out.tfevents.1712573969.5987425793bc.2443.267  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q3/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q3/events.out.tfevents.1712573968.5987425793bc.2443.258  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_min/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_min/events.out.tfevents.1712574317.5987425793bc.2443.272  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_max/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_max/events.out.tfevents.1712574317.5987425793bc.2443.276  \n"
          ]
        }
      ],
      "source": [
        "#!unzip ff_filters_errors.zip\n",
        "!unzip ff_diffs.zip\n",
        "!unzip ff_diffs_errors.zip\n",
        "!unzip cnn1d_no_filters.zip\n",
        "!unzip cnn1d_no_diffs.zip\n",
        "!unzip cnn1d_with_filters.zip\n",
        "!unzip cnn1d_with_diffs.zip\n",
        "!unzip cnn1d_stack_filters.zip\n",
        "!unzip cnn1d_stack_diffs.zip"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
