{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4RB7GVHUjKG",
        "outputId": "1dcc7926-c601-465c-ff3e-181ddaa006b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'custom-pytorch-lightning-module'...\n",
            "remote: Enumerating objects: 46, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 46 (delta 25), reused 28 (delta 13), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (46/46), 22.47 KiB | 1.32 MiB/s, done.\n",
            "Resolving deltas: 100% (25/25), done.\n",
            "Cloning into 'pytorch-blocks'...\n",
            "remote: Enumerating objects: 29, done.\u001b[K\n",
            "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 29 (delta 15), reused 18 (delta 8), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (29/29), 20.19 KiB | 1.19 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/lucas-battisti/custom-pytorch-lightning-module.git\n",
        "!mv \"custom-pytorch-lightning-module/modules.py\" \"modules.py\"\n",
        "!rm -rf \"custom-pytorch-lightning-module\"\n",
        "\n",
        "\n",
        "\n",
        "!git clone https://github.com/lucas-battisti/pytorch-blocks.git\n",
        "!mv \"pytorch-blocks/blocks.py\" \"blocks.py\"\n",
        "!rm -rf \"pytorch-blocks\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "epjII3SgUjKL"
      },
      "outputs": [],
      "source": [
        "import dt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RA</th>\n",
              "      <th>DEC</th>\n",
              "      <th>MU_MAX_INST</th>\n",
              "      <th>FWHM_n</th>\n",
              "      <th>PhotoFlagDet</th>\n",
              "      <th>u_PStotal</th>\n",
              "      <th>e_u_PStotal</th>\n",
              "      <th>J0378_PStotal</th>\n",
              "      <th>e_J0378_PStotal</th>\n",
              "      <th>J0395_PStotal</th>\n",
              "      <th>...</th>\n",
              "      <th>nDet_PStotal</th>\n",
              "      <th>W1_MAG</th>\n",
              "      <th>W2_MAG</th>\n",
              "      <th>e_W1_MAG</th>\n",
              "      <th>e_W2_MAG</th>\n",
              "      <th>FUVmag</th>\n",
              "      <th>NUVmag</th>\n",
              "      <th>e_FUVmag</th>\n",
              "      <th>e_NUVmag</th>\n",
              "      <th>Z</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>iDR5_3_0_STRIPE82-0074_0030854</th>\n",
              "      <td>50.950031</td>\n",
              "      <td>0.691337</td>\n",
              "      <td>19.122868</td>\n",
              "      <td>1.744728</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.855314</td>\n",
              "      <td>0.224955</td>\n",
              "      <td>21.838514</td>\n",
              "      <td>0.311987</td>\n",
              "      <td>21.972036</td>\n",
              "      <td>...</td>\n",
              "      <td>12.0</td>\n",
              "      <td>19.123713</td>\n",
              "      <td>19.291985</td>\n",
              "      <td>0.033687</td>\n",
              "      <td>0.083541</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.247318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>iDR5_3_SPLUS-n02s48_0031444</th>\n",
              "      <td>214.704224</td>\n",
              "      <td>-1.127490</td>\n",
              "      <td>18.499992</td>\n",
              "      <td>2.070420</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.384974</td>\n",
              "      <td>0.452150</td>\n",
              "      <td>21.922901</td>\n",
              "      <td>0.671358</td>\n",
              "      <td>20.816227</td>\n",
              "      <td>...</td>\n",
              "      <td>12.0</td>\n",
              "      <td>18.894621</td>\n",
              "      <td>19.056978</td>\n",
              "      <td>0.025455</td>\n",
              "      <td>0.062376</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.181604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>iDR5_3_0_STRIPE82-0023_0033419</th>\n",
              "      <td>15.010666</td>\n",
              "      <td>-0.082431</td>\n",
              "      <td>20.077642</td>\n",
              "      <td>1.923943</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21.636702</td>\n",
              "      <td>...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>18.399147</td>\n",
              "      <td>19.160164</td>\n",
              "      <td>0.019780</td>\n",
              "      <td>0.081629</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.639951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>iDR5_3_SPLUS-n01s22_0038877</th>\n",
              "      <td>179.694824</td>\n",
              "      <td>0.403215</td>\n",
              "      <td>18.557959</td>\n",
              "      <td>1.640066</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.573034</td>\n",
              "      <td>2.673750</td>\n",
              "      <td>22.158922</td>\n",
              "      <td>0.911359</td>\n",
              "      <td>21.302311</td>\n",
              "      <td>...</td>\n",
              "      <td>12.0</td>\n",
              "      <td>18.828346</td>\n",
              "      <td>18.827257</td>\n",
              "      <td>0.027340</td>\n",
              "      <td>0.058215</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.226022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>iDR5_3_0_STRIPE82-0169_0034291</th>\n",
              "      <td>358.984741</td>\n",
              "      <td>-0.114401</td>\n",
              "      <td>18.403070</td>\n",
              "      <td>1.551156</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.509279</td>\n",
              "      <td>0.727081</td>\n",
              "      <td>20.962872</td>\n",
              "      <td>0.447041</td>\n",
              "      <td>21.956846</td>\n",
              "      <td>...</td>\n",
              "      <td>12.0</td>\n",
              "      <td>18.533161</td>\n",
              "      <td>18.838491</td>\n",
              "      <td>0.020226</td>\n",
              "      <td>0.054294</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.137109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>iDR5_3_0_STRIPE82_0128_0032437</th>\n",
              "      <td>328.602417</td>\n",
              "      <td>0.698312</td>\n",
              "      <td>18.618523</td>\n",
              "      <td>5.217855</td>\n",
              "      <td>3.0</td>\n",
              "      <td>22.137739</td>\n",
              "      <td>21.924606</td>\n",
              "      <td>21.631830</td>\n",
              "      <td>22.472164</td>\n",
              "      <td>21.187452</td>\n",
              "      <td>...</td>\n",
              "      <td>12.0</td>\n",
              "      <td>17.693741</td>\n",
              "      <td>18.143261</td>\n",
              "      <td>0.010276</td>\n",
              "      <td>0.030319</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.209080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>iDR5_3_0_STRIPE82-0120_0012890</th>\n",
              "      <td>323.410156</td>\n",
              "      <td>0.363115</td>\n",
              "      <td>17.319054</td>\n",
              "      <td>2.877129</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.417023</td>\n",
              "      <td>1.007946</td>\n",
              "      <td>21.958624</td>\n",
              "      <td>0.881726</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>11.0</td>\n",
              "      <td>17.536827</td>\n",
              "      <td>17.679157</td>\n",
              "      <td>0.009996</td>\n",
              "      <td>0.021091</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.371750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>iDR5_3_SPLUS-s35s31_0028721</th>\n",
              "      <td>57.084660</td>\n",
              "      <td>-45.228428</td>\n",
              "      <td>20.006327</td>\n",
              "      <td>1.954982</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>24.126984</td>\n",
              "      <td>6.650383</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>20.031857</td>\n",
              "      <td>20.208897</td>\n",
              "      <td>0.054559</td>\n",
              "      <td>0.129773</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.354642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>iDR5_3_SPLUS-n01s53_0012668</th>\n",
              "      <td>221.093491</td>\n",
              "      <td>-0.366121</td>\n",
              "      <td>20.360678</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.918537</td>\n",
              "      <td>3.044804</td>\n",
              "      <td>23.033947</td>\n",
              "      <td>1.964511</td>\n",
              "      <td>23.556732</td>\n",
              "      <td>...</td>\n",
              "      <td>11.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.947900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>iDR5_3_SPLUS-n10s43_0067191</th>\n",
              "      <td>209.366104</td>\n",
              "      <td>-11.647486</td>\n",
              "      <td>19.821095</td>\n",
              "      <td>1.958159</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.625282</td>\n",
              "      <td>0.717106</td>\n",
              "      <td>22.703548</td>\n",
              "      <td>0.920679</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>11.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.063857</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>590262 rows Ã— 39 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        RA        DEC  MU_MAX_INST    FWHM_n  \\\n",
              "ID                                                                             \n",
              "iDR5_3_0_STRIPE82-0074_0030854   50.950031   0.691337    19.122868  1.744728   \n",
              "iDR5_3_SPLUS-n02s48_0031444     214.704224  -1.127490    18.499992  2.070420   \n",
              "iDR5_3_0_STRIPE82-0023_0033419   15.010666  -0.082431    20.077642  1.923943   \n",
              "iDR5_3_SPLUS-n01s22_0038877     179.694824   0.403215    18.557959  1.640066   \n",
              "iDR5_3_0_STRIPE82-0169_0034291  358.984741  -0.114401    18.403070  1.551156   \n",
              "...                                    ...        ...          ...       ...   \n",
              "iDR5_3_0_STRIPE82_0128_0032437  328.602417   0.698312    18.618523  5.217855   \n",
              "iDR5_3_0_STRIPE82-0120_0012890  323.410156   0.363115    17.319054  2.877129   \n",
              "iDR5_3_SPLUS-s35s31_0028721      57.084660 -45.228428    20.006327  1.954982   \n",
              "iDR5_3_SPLUS-n01s53_0012668     221.093491  -0.366121    20.360678  0.000000   \n",
              "iDR5_3_SPLUS-n10s43_0067191     209.366104 -11.647486    19.821095  1.958159   \n",
              "\n",
              "                                PhotoFlagDet  u_PStotal  e_u_PStotal  \\\n",
              "ID                                                                     \n",
              "iDR5_3_0_STRIPE82-0074_0030854           0.0  21.855314     0.224955   \n",
              "iDR5_3_SPLUS-n02s48_0031444              0.0  21.384974     0.452150   \n",
              "iDR5_3_0_STRIPE82-0023_0033419           0.0        NaN          NaN   \n",
              "iDR5_3_SPLUS-n01s22_0038877              0.0  23.573034     2.673750   \n",
              "iDR5_3_0_STRIPE82-0169_0034291           0.0  21.509279     0.727081   \n",
              "...                                      ...        ...          ...   \n",
              "iDR5_3_0_STRIPE82_0128_0032437           3.0  22.137739    21.924606   \n",
              "iDR5_3_0_STRIPE82-0120_0012890           0.0  22.417023     1.007946   \n",
              "iDR5_3_SPLUS-s35s31_0028721              0.0        NaN          NaN   \n",
              "iDR5_3_SPLUS-n01s53_0012668              0.0  23.918537     3.044804   \n",
              "iDR5_3_SPLUS-n10s43_0067191              0.0  22.625282     0.717106   \n",
              "\n",
              "                                J0378_PStotal  e_J0378_PStotal  J0395_PStotal  \\\n",
              "ID                                                                              \n",
              "iDR5_3_0_STRIPE82-0074_0030854      21.838514         0.311987      21.972036   \n",
              "iDR5_3_SPLUS-n02s48_0031444         21.922901         0.671358      20.816227   \n",
              "iDR5_3_0_STRIPE82-0023_0033419            NaN              NaN      21.636702   \n",
              "iDR5_3_SPLUS-n01s22_0038877         22.158922         0.911359      21.302311   \n",
              "iDR5_3_0_STRIPE82-0169_0034291      20.962872         0.447041      21.956846   \n",
              "...                                       ...              ...            ...   \n",
              "iDR5_3_0_STRIPE82_0128_0032437      21.631830        22.472164      21.187452   \n",
              "iDR5_3_0_STRIPE82-0120_0012890      21.958624         0.881726            NaN   \n",
              "iDR5_3_SPLUS-s35s31_0028721         24.126984         6.650383            NaN   \n",
              "iDR5_3_SPLUS-n01s53_0012668         23.033947         1.964511      23.556732   \n",
              "iDR5_3_SPLUS-n10s43_0067191         22.703548         0.920679            NaN   \n",
              "\n",
              "                                ...  nDet_PStotal     W1_MAG     W2_MAG  \\\n",
              "ID                              ...                                       \n",
              "iDR5_3_0_STRIPE82-0074_0030854  ...          12.0  19.123713  19.291985   \n",
              "iDR5_3_SPLUS-n02s48_0031444     ...          12.0  18.894621  19.056978   \n",
              "iDR5_3_0_STRIPE82-0023_0033419  ...          10.0  18.399147  19.160164   \n",
              "iDR5_3_SPLUS-n01s22_0038877     ...          12.0  18.828346  18.827257   \n",
              "iDR5_3_0_STRIPE82-0169_0034291  ...          12.0  18.533161  18.838491   \n",
              "...                             ...           ...        ...        ...   \n",
              "iDR5_3_0_STRIPE82_0128_0032437  ...          12.0  17.693741  18.143261   \n",
              "iDR5_3_0_STRIPE82-0120_0012890  ...          11.0  17.536827  17.679157   \n",
              "iDR5_3_SPLUS-s35s31_0028721     ...           9.0  20.031857  20.208897   \n",
              "iDR5_3_SPLUS-n01s53_0012668     ...          11.0        NaN        NaN   \n",
              "iDR5_3_SPLUS-n10s43_0067191     ...          11.0        NaN        NaN   \n",
              "\n",
              "                                e_W1_MAG  e_W2_MAG  FUVmag  NUVmag  e_FUVmag  \\\n",
              "ID                                                                             \n",
              "iDR5_3_0_STRIPE82-0074_0030854  0.033687  0.083541     NaN     NaN       NaN   \n",
              "iDR5_3_SPLUS-n02s48_0031444     0.025455  0.062376     NaN     NaN       NaN   \n",
              "iDR5_3_0_STRIPE82-0023_0033419  0.019780  0.081629     NaN     NaN       NaN   \n",
              "iDR5_3_SPLUS-n01s22_0038877     0.027340  0.058215     NaN     NaN       NaN   \n",
              "iDR5_3_0_STRIPE82-0169_0034291  0.020226  0.054294     NaN     NaN       NaN   \n",
              "...                                  ...       ...     ...     ...       ...   \n",
              "iDR5_3_0_STRIPE82_0128_0032437  0.010276  0.030319     NaN     NaN       NaN   \n",
              "iDR5_3_0_STRIPE82-0120_0012890  0.009996  0.021091     NaN     NaN       NaN   \n",
              "iDR5_3_SPLUS-s35s31_0028721     0.054559  0.129773     NaN     NaN       NaN   \n",
              "iDR5_3_SPLUS-n01s53_0012668          NaN       NaN     NaN     NaN       NaN   \n",
              "iDR5_3_SPLUS-n10s43_0067191          NaN       NaN     NaN     NaN       NaN   \n",
              "\n",
              "                                e_NUVmag         Z  \n",
              "ID                                                  \n",
              "iDR5_3_0_STRIPE82-0074_0030854       NaN  0.247318  \n",
              "iDR5_3_SPLUS-n02s48_0031444          NaN  0.181604  \n",
              "iDR5_3_0_STRIPE82-0023_0033419       NaN  0.639951  \n",
              "iDR5_3_SPLUS-n01s22_0038877          NaN  0.226022  \n",
              "iDR5_3_0_STRIPE82-0169_0034291       NaN  0.137109  \n",
              "...                                  ...       ...  \n",
              "iDR5_3_0_STRIPE82_0128_0032437       NaN  0.209080  \n",
              "iDR5_3_0_STRIPE82-0120_0012890       NaN  0.371750  \n",
              "iDR5_3_SPLUS-s35s31_0028721          NaN  0.354642  \n",
              "iDR5_3_SPLUS-n01s53_0012668          NaN  0.947900  \n",
              "iDR5_3_SPLUS-n10s43_0067191          NaN  0.063857  \n",
              "\n",
              "[590262 rows x 39 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "df = pd.read_csv('data/galax.csv').drop('ID', axis=1).astype('float32')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "AGz22PvSUjKL"
      },
      "outputs": [],
      "source": [
        "set_size = [0.6, 0.2, 0.2]\n",
        "\n",
        "df = pd.read_csv('data/galax.csv').drop('ID', axis=1).astype('float32')\n",
        "\n",
        "dtfr = dt.frame(df = df,\n",
        "         set_size=set_size)\n",
        "\n",
        "f = dtfr.features(['g', 'j','u'])['complete']\n",
        "e_f = dtfr.features(['e_g', 'e_j','e_u'])['complete']\n",
        "\n",
        "z = dtfr.features(['z'])['complete']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "HUmniuEKUjKM"
      },
      "outputs": [],
      "source": [
        "import lightning as L\n",
        "\n",
        "from modules import RegressionModule as Reg\n",
        "from blocks import LinearBlock, Conv1dBlock, Conv2dBlock\n",
        "from data import FF_Dataset, Custom_DataModule, CNN1D_Dataset, CNN2D_Dataset\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import MaxPool1d, AvgPool1d\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "from math import floor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "I7QCD5oCUjKM"
      },
      "outputs": [],
      "source": [
        "dm = {}\n",
        "m = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2L4YWgh7UjKN"
      },
      "source": [
        "# FF with filters and no errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HU0h2Kf4UjKO",
        "outputId": "40ea1758-d40a-492c-a781-db4f8a4a9485"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "2024-05-08 08:01:13.545457: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-05-08 08:01:14.196437: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-05-08 08:01:15.631421: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 421   \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "421       Trainable params\n",
            "0         Non-trainable params\n",
            "421       Total params\n",
            "0.002     Total estimated model params size (MB)\n",
            "/home/lucas-battisti/miniconda3/envs/Acnodnem-Ailiram/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "/home/lucas-battisti/miniconda3/envs/Acnodnem-Ailiram/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
          ]
        }
      ],
      "source": [
        "str = 'ff_filters'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (f, None, z),\n",
        "                       dataset_class=FF_Dataset,\n",
        "                       norm=True,\n",
        "                       set_size=set_size,\n",
        "                       batch_size=200, num_workers=1)\n",
        "\n",
        "l1 = LinearBlock(in_features=16, out_features=12,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 12},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=12, out_features=12,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 12},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=12, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=250,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GPFYFJjUjKQ"
      },
      "source": [
        "# FF with filters and errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqRRkyg1UjKQ",
        "outputId": "9909348e-e9f0-4269-e95a-756b8e1847e0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 1.5 K \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "1.5 K     Trainable params\n",
            "0         Non-trainable params\n",
            "1.5 K     Total params\n",
            "0.006     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 1.5 K \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "1.5 K     Trainable params\n",
            "0         Non-trainable params\n",
            "1.5 K     Total params\n",
            "0.006     Total estimated model params size (MB)\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str = 'ff_filters_errors'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (f, e_f, z),\n",
        "                       dataset_class=FF_Dataset,\n",
        "                       norm=True,\n",
        "                       set_size=set_size,\n",
        "                       batch_size=200, num_workers=1)\n",
        "\n",
        "l1 = LinearBlock(in_features=32, out_features=24,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 24},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=24, out_features=24,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 24},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=24, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=250,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOHtZ7pyUjKR"
      },
      "source": [
        "# FF with diffs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCH7erbXUjKR",
        "outputId": "33fe0012-6a58-4b14-bfce-34a0ce1bfe2b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 409   \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "409       Trainable params\n",
            "0         Non-trainable params\n",
            "409       Total params\n",
            "0.002     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 409   \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "409       Trainable params\n",
            "0         Non-trainable params\n",
            "409       Total params\n",
            "0.002     Total estimated model params size (MB)\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str = 'ff_diffs'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (d, None, z),\n",
        "                       dataset_class=FF_Dataset,\n",
        "                       norm=True,\n",
        "                       set_size=set_size,\n",
        "                       batch_size=200, num_workers=1)\n",
        "\n",
        "l1 = LinearBlock(in_features=15, out_features=12,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 12},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=12, out_features=12,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 12},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=12, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=250,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkRvbNlVUjKT"
      },
      "source": [
        "# FF with diffs and errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMT1fdvEUjKT",
        "outputId": "c0f8d220-8da6-4c66-de1b-0a7e02a04089"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 1.5 K \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "1.5 K     Trainable params\n",
            "0         Non-trainable params\n",
            "1.5 K     Total params\n",
            "0.006     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 1.5 K \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "1.5 K     Trainable params\n",
            "0         Non-trainable params\n",
            "1.5 K     Total params\n",
            "0.006     Total estimated model params size (MB)\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str = 'ff_diffs_errors'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (d, e_d, z),\n",
        "                       dataset_class=FF_Dataset,\n",
        "                       norm=True,\n",
        "                       set_size=set_size,\n",
        "                       batch_size=200, num_workers=1)\n",
        "\n",
        "l1 = LinearBlock(in_features=30, out_features=24,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 24},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=24, out_features=24,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 24},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=24, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=250,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yxGFV4fUjKU"
      },
      "source": [
        "# CNN1D_no with filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6MzCRSxUjKU",
        "outputId": "4027079e-8396-4000-bd12-61541f94aa4c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 53.9 K\n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "53.9 K    Trainable params\n",
            "0         Non-trainable params\n",
            "53.9 K    Total params\n",
            "0.215     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 53.9 K\n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "53.9 K    Trainable params\n",
            "0         Non-trainable params\n",
            "53.9 K    Total params\n",
            "0.215     Total estimated model params size (MB)\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str = 'cnn1d_no_filters'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (f, e_f, z),\n",
        "                       dataset_class=CNN1D_Dataset,\n",
        "                       version='no', norm=True,\n",
        "                       set_size=set_size,\n",
        "                       batch_size=200, num_workers=1)\n",
        "\n",
        "c1 = Conv1dBlock(in_channels=1, out_channels=32,\n",
        "                 kernel_size=3,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 32},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "c2 = Conv1dBlock(in_channels=32, out_channels=64,\n",
        "                 kernel_size=2,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 64},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "flatten = nn.Flatten()\n",
        "\n",
        "l1 = LinearBlock(in_features=192, out_features=144,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 144},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=144, out_features=144,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 144},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=144, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(c1, c2, flatten,\n",
        "                           l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=250,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6XRrCBIUjKU"
      },
      "source": [
        "# CNN1D_no with diffs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZEysR5sUjKV",
        "outputId": "0f652dfe-f493-42d1-ba19-886893570a0c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 44.7 K\n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "44.7 K    Trainable params\n",
            "0         Non-trainable params\n",
            "44.7 K    Total params\n",
            "0.179     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 44.7 K\n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "44.7 K    Trainable params\n",
            "0         Non-trainable params\n",
            "44.7 K    Total params\n",
            "0.179     Total estimated model params size (MB)\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str = 'cnn1d_no_diffs'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (d, e_d, z),\n",
        "                       dataset_class=CNN1D_Dataset,\n",
        "                       version='no', norm=True,\n",
        "                       set_size=set_size,\n",
        "                       batch_size=200, num_workers=1)\n",
        "\n",
        "c1 = Conv1dBlock(in_channels=1, out_channels=32,\n",
        "                 kernel_size=3,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 32},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "c2 = Conv1dBlock(in_channels=32, out_channels=64,\n",
        "                 kernel_size=2,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 64},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "flatten = nn.Flatten()\n",
        "\n",
        "l1 = LinearBlock(in_features=128, out_features=144,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 144},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=144, out_features=144,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 144},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=144, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(c1, c2, flatten,\n",
        "                           l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=250,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfamPT7-UjKV"
      },
      "source": [
        "# CNN1D_with with filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSi-_JD9UjKW",
        "outputId": "5364453e-118a-4b54-dbf1-816a22a71f93"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 270 K \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "270 K     Trainable params\n",
            "0         Non-trainable params\n",
            "270 K     Total params\n",
            "1.081     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 270 K \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "270 K     Trainable params\n",
            "0         Non-trainable params\n",
            "270 K     Total params\n",
            "1.081     Total estimated model params size (MB)\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str = 'cnn1d_with_filters'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (f, e_f, z),\n",
        "                       dataset_class=CNN1D_Dataset,\n",
        "                       version='with', norm=True,\n",
        "                       set_size=set_size,\n",
        "                       batch_size=200, num_workers=1)\n",
        "\n",
        "c1 = Conv1dBlock(in_channels=1, out_channels=32,\n",
        "                 kernel_size=3,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 32},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "c2 = Conv1dBlock(in_channels=32, out_channels=64,\n",
        "                 kernel_size=2,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 64},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "flatten = nn.Flatten()\n",
        "\n",
        "l1 = LinearBlock(in_features=448, out_features=336,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 336},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=336, out_features=336,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 336},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=336, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(c1, c2, flatten,\n",
        "                           l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=250,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYlhEzakUjKW"
      },
      "source": [
        "# CNN1D_with with diffs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ovm2BQF-UjKW",
        "outputId": "ad5bba48-3eb5-4c5d-e9e9-ebaca93e48a9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 248 K \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "248 K     Trainable params\n",
            "0         Non-trainable params\n",
            "248 K     Total params\n",
            "0.995     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 248 K \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "248 K     Trainable params\n",
            "0         Non-trainable params\n",
            "248 K     Total params\n",
            "0.995     Total estimated model params size (MB)\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str = 'cnn1d_with_diffs'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (d, e_d, z),\n",
        "                       dataset_class=CNN1D_Dataset,\n",
        "                       version='with', norm=True,\n",
        "                       set_size=set_size,\n",
        "                       batch_size=200, num_workers=1)\n",
        "\n",
        "c1 = Conv1dBlock(in_channels=1, out_channels=32,\n",
        "                 kernel_size=3,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 32},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "c2 = Conv1dBlock(in_channels=32, out_channels=64,\n",
        "                 kernel_size=2,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 64},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "flatten = nn.Flatten()\n",
        "\n",
        "l1 = LinearBlock(in_features=384, out_features=336,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 336},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=336, out_features=336,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 336},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=336, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(c1, c2, flatten,\n",
        "                           l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,max_epochs=250\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=250,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suaAYcQfUjKX"
      },
      "source": [
        "# CNN1D_stack with filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2L7x7jfJUjKX",
        "outputId": "635b3bb3-1d2b-4e2c-e3d1-b6c8942a1b5f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 54.0 K\n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "54.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "54.0 K    Total params\n",
            "0.216     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 54.0 K\n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "54.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "54.0 K    Total params\n",
            "0.216     Total estimated model params size (MB)\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str = 'cnn1d_stack_filters'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (f, e_f, z),\n",
        "                       dataset_class=CNN1D_Dataset,\n",
        "                       version='stack', norm=True,\n",
        "                       set_size=set_size,\n",
        "                       batch_size=200, num_workers=1)\n",
        "\n",
        "c1 = Conv1dBlock(in_channels=2, out_channels=32,\n",
        "                 kernel_size=3,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 32},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "c2 = Conv1dBlock(in_channels=32, out_channels=64,\n",
        "                 kernel_size=2,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 64},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "flatten = nn.Flatten()\n",
        "\n",
        "l1 = LinearBlock(in_features=192, out_features=144,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 144},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=144, out_features=144,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 144},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=144, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(c1, c2, flatten,\n",
        "                           l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=250,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-yDhG1SUjKY"
      },
      "source": [
        "# CNN1D_stack with diffs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AilGuS8CUjKY",
        "outputId": "f54d66ae-7697-4196-bb5a-932e1300bee3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 46.9 K\n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "46.9 K    Trainable params\n",
            "0         Non-trainable params\n",
            "46.9 K    Total params\n",
            "0.187     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 46.9 K\n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "46.9 K    Trainable params\n",
            "0         Non-trainable params\n",
            "46.9 K    Total params\n",
            "0.187     Total estimated model params size (MB)\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str = 'cnn1d_stack_diffs'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (d, e_d, z),\n",
        "                       dataset_class=CNN1D_Dataset,\n",
        "                       version='stack', norm=True,\n",
        "                       set_size=set_size,\n",
        "                       batch_size=200, num_workers=1)\n",
        "\n",
        "c1 = Conv1dBlock(in_channels=2, out_channels=32,\n",
        "                 kernel_size=4,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 32},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "c2 = Conv1dBlock(in_channels=32, out_channels=64,\n",
        "                 kernel_size=3,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 64},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "flatten = nn.Flatten()\n",
        "\n",
        "l1 = LinearBlock(in_features=128, out_features=144,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 144},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=144, out_features=144,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 144},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=144, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(c1, c2, flatten,\n",
        "                           l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=250,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPGIRVW-UjKY"
      },
      "source": [
        "# CNN2D with filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLgl75pxUjKY",
        "outputId": "6078749c-5841-4e2e-a55a-5f6d84b2e325"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: False, used: False\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: \n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 214 K \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "214 K     Trainable params\n",
            "0         Non-trainable params\n",
            "214 K     Total params\n",
            "0.859     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 214 K \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "214 K     Trainable params\n",
            "0         Non-trainable params\n",
            "214 K     Total params\n",
            "0.859     Total estimated model params size (MB)\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=175` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=175` reached.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str = 'cnn2d_filters'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (f, e_f, z),\n",
        "                       dataset_class=CNN2D_Dataset,\n",
        "                       K=20, t_inf=10, t_sup=10, norm=True,\n",
        "                       set_size=set_size,\n",
        "                       batch_size=200, num_workers=1)\n",
        "\n",
        "c1 = Conv2dBlock(in_channels=1, out_channels=32,\n",
        "                 kernel_size=4,\n",
        "                 norm_layer=nn.BatchNorm2d, norm_layer_args={'num_features': 32},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=nn.MaxPool2d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "c2 = Conv2dBlock(in_channels=32, out_channels=64,\n",
        "                 kernel_size=3,\n",
        "                 norm_layer=nn.BatchNorm2d, norm_layer_args={'num_features': 64},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=nn.MaxPool2d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "flatten = nn.Flatten()\n",
        "\n",
        "l1 = LinearBlock(in_features=384, out_features=288,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 288},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=288, out_features=288,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 288},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=288, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(c1, c2, flatten,\n",
        "                           l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=175,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OocjQ0b-UjKZ"
      },
      "source": [
        "# CNN2D with diffs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEFIEFUqUjKZ",
        "outputId": "37df4bf2-474f-418a-af15-d4ed1715a54e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: False, used: False\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: \n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 159 K \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "159 K     Trainable params\n",
            "0         Non-trainable params\n",
            "159 K     Total params\n",
            "0.639     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 159 K \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "159 K     Trainable params\n",
            "0         Non-trainable params\n",
            "159 K     Total params\n",
            "0.639     Total estimated model params size (MB)\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=250` reached.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str = 'cnn2d_diffs'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (d, e_d, z),\n",
        "                       dataset_class=CNN2D_Dataset,\n",
        "                       K=20, t_inf=10, t_sup=10, norm=True,\n",
        "                       set_size=set_size,\n",
        "                       batch_size=200, num_workers=1)\n",
        "\n",
        "c1 = Conv2dBlock(in_channels=1, out_channels=32,\n",
        "                 kernel_size=5,\n",
        "                 norm_layer=nn.BatchNorm2d, norm_layer_args={'num_features': 32},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=nn.MaxPool2d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "c2 = Conv2dBlock(in_channels=32, out_channels=64,\n",
        "                 kernel_size=3,\n",
        "                 norm_layer=nn.BatchNorm2d, norm_layer_args={'num_features': 64},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=nn.MaxPool2d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "flatten = nn.Flatten()\n",
        "\n",
        "l1 = LinearBlock(in_features=192, out_features=288,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 288},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=288, out_features=288,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 288},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=288, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(c1, c2, flatten,\n",
        "                           l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=250,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eA-6znM63seE",
        "outputId": "c2a43897-c7a7-4bba-9fd2-53e9d8f3f345"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: ff_filters/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_std/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_std/events.out.tfevents.1712597390.605934e206d9.368.26 (deflated 10%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_mean/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_mean/events.out.tfevents.1712597079.605934e206d9.368.17 (deflated 74%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_size/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_size/events.out.tfevents.1712597390.605934e206d9.368.27 (deflated 10%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_median/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_median/events.out.tfevents.1712597077.605934e206d9.368.5 (deflated 76%)\n",
            "  adding: ff_filters/lightning_logs/version_0/losses_validation_loss/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/losses_validation_loss/events.out.tfevents.1712597077.605934e206d9.368.2 (deflated 63%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_min/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_min/events.out.tfevents.1712597390.605934e206d9.368.20 (deflated 10%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_min/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_min/events.out.tfevents.1712597079.605934e206d9.368.12 (deflated 76%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_q3/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_q3/events.out.tfevents.1712597077.605934e206d9.368.6 (deflated 76%)\n",
            "  adding: ff_filters/lightning_logs/version_0/losses_training_loss/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/losses_training_loss/events.out.tfevents.1712597079.605934e206d9.368.11 (deflated 63%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_std/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_std/events.out.tfevents.1712597079.605934e206d9.368.18 (deflated 74%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_max/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_max/events.out.tfevents.1712597390.605934e206d9.368.24 (deflated 10%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_q1/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_q1/events.out.tfevents.1712597390.605934e206d9.368.21 (deflated 10%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_max/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_max/events.out.tfevents.1712597077.605934e206d9.368.7 (deflated 76%)\n",
            "  adding: ff_filters/lightning_logs/version_0/events.out.tfevents.1712597077.605934e206d9.368.1 (deflated 5%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_mean/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_mean/events.out.tfevents.1712597390.605934e206d9.368.25 (deflated 10%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_q1/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_q1/events.out.tfevents.1712597077.605934e206d9.368.4 (deflated 76%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_q3/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_q3/events.out.tfevents.1712597390.605934e206d9.368.23 (deflated 10%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_mean/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_mean/events.out.tfevents.1712597077.605934e206d9.368.8 (deflated 76%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_q3/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_q3/events.out.tfevents.1712597079.605934e206d9.368.15 (deflated 74%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_std/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_std/events.out.tfevents.1712597077.605934e206d9.368.9 (deflated 76%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_q1/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_q1/events.out.tfevents.1712597079.605934e206d9.368.13 (deflated 74%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_size/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_size/events.out.tfevents.1712597079.605934e206d9.368.19 (deflated 79%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_median/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_median/events.out.tfevents.1712597390.605934e206d9.368.22 (deflated 10%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_max/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_max/events.out.tfevents.1712597079.605934e206d9.368.16 (deflated 74%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_median/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_median/events.out.tfevents.1712597079.605934e206d9.368.14 (deflated 74%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_min/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_min/events.out.tfevents.1712597077.605934e206d9.368.3 (deflated 76%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_size/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_size/events.out.tfevents.1712597077.605934e206d9.368.10 (deflated 81%)\n",
            "  adding: cnn2d_filters/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_std/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_std/events.out.tfevents.1712602014.605934e206d9.368.110 (deflated 9%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_mean/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_mean/events.out.tfevents.1712600262.605934e206d9.368.101 (deflated 72%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_size/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_size/events.out.tfevents.1712602014.605934e206d9.368.111 (deflated 9%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_median/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_median/events.out.tfevents.1712600251.605934e206d9.368.89 (deflated 74%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/losses_validation_loss/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/losses_validation_loss/events.out.tfevents.1712600251.605934e206d9.368.86 (deflated 61%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_min/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_min/events.out.tfevents.1712602014.605934e206d9.368.104 (deflated 9%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_min/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_min/events.out.tfevents.1712600262.605934e206d9.368.96 (deflated 74%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_q3/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_q3/events.out.tfevents.1712600251.605934e206d9.368.90 (deflated 74%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/losses_training_loss/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/losses_training_loss/events.out.tfevents.1712600262.605934e206d9.368.95 (deflated 60%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_std/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_std/events.out.tfevents.1712600262.605934e206d9.368.102 (deflated 72%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_max/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_max/events.out.tfevents.1712602014.605934e206d9.368.108 (deflated 9%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_q1/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_q1/events.out.tfevents.1712602014.605934e206d9.368.105 (deflated 9%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/events.out.tfevents.1712600251.605934e206d9.368.85 (deflated 4%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_max/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_max/events.out.tfevents.1712600251.605934e206d9.368.91 (deflated 74%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_mean/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_mean/events.out.tfevents.1712602014.605934e206d9.368.109 (deflated 9%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_q1/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_q1/events.out.tfevents.1712600251.605934e206d9.368.88 (deflated 74%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_q3/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_q3/events.out.tfevents.1712602014.605934e206d9.368.107 (deflated 9%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_mean/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_mean/events.out.tfevents.1712600251.605934e206d9.368.92 (deflated 74%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_q3/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_q3/events.out.tfevents.1712600262.605934e206d9.368.99 (deflated 72%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_std/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_std/events.out.tfevents.1712600251.605934e206d9.368.93 (deflated 74%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_q1/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_q1/events.out.tfevents.1712600262.605934e206d9.368.97 (deflated 72%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_size/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_size/events.out.tfevents.1712600262.605934e206d9.368.103 (deflated 78%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_median/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_median/events.out.tfevents.1712602014.605934e206d9.368.106 (deflated 9%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_max/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_max/events.out.tfevents.1712600262.605934e206d9.368.100 (deflated 72%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_median/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_median/events.out.tfevents.1712600262.605934e206d9.368.98 (deflated 72%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_min/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_min/events.out.tfevents.1712600251.605934e206d9.368.87 (deflated 74%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_size/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_size/events.out.tfevents.1712600251.605934e206d9.368.94 (deflated 79%)\n",
            "  adding: cnn2d_diffs/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_std/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_std/events.out.tfevents.1712600249.605934e206d9.368.82 (deflated 10%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_mean/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_mean/events.out.tfevents.1712597858.605934e206d9.368.73 (deflated 73%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_size/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_size/events.out.tfevents.1712600249.605934e206d9.368.83 (deflated 10%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_median/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_median/events.out.tfevents.1712597849.605934e206d9.368.61 (deflated 75%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/losses_validation_loss/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/losses_validation_loss/events.out.tfevents.1712597849.605934e206d9.368.58 (deflated 61%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_min/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_min/events.out.tfevents.1712600249.605934e206d9.368.76 (deflated 10%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_min/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_min/events.out.tfevents.1712597858.605934e206d9.368.68 (deflated 75%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q3/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q3/events.out.tfevents.1712597849.605934e206d9.368.62 (deflated 75%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/losses_training_loss/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/losses_training_loss/events.out.tfevents.1712597858.605934e206d9.368.67 (deflated 61%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_std/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_std/events.out.tfevents.1712597858.605934e206d9.368.74 (deflated 73%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_max/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_max/events.out.tfevents.1712600249.605934e206d9.368.80 (deflated 10%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_q1/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_q1/events.out.tfevents.1712600249.605934e206d9.368.77 (deflated 10%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_max/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_max/events.out.tfevents.1712597849.605934e206d9.368.63 (deflated 75%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_mean/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_mean/events.out.tfevents.1712600249.605934e206d9.368.81 (deflated 10%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q1/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q1/events.out.tfevents.1712597849.605934e206d9.368.60 (deflated 75%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_q3/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_q3/events.out.tfevents.1712600249.605934e206d9.368.79 (deflated 10%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_mean/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_mean/events.out.tfevents.1712597849.605934e206d9.368.64 (deflated 75%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_q3/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_q3/events.out.tfevents.1712597858.605934e206d9.368.71 (deflated 73%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_std/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_std/events.out.tfevents.1712597849.605934e206d9.368.65 (deflated 75%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_q1/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_q1/events.out.tfevents.1712597858.605934e206d9.368.69 (deflated 73%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_size/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_size/events.out.tfevents.1712597858.605934e206d9.368.75 (deflated 78%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_median/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_median/events.out.tfevents.1712600249.605934e206d9.368.78 (deflated 10%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_max/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_max/events.out.tfevents.1712597858.605934e206d9.368.72 (deflated 73%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/events.out.tfevents.1712597849.605934e206d9.368.57 (deflated 5%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_median/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_median/events.out.tfevents.1712597858.605934e206d9.368.70 (deflated 73%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_min/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_min/events.out.tfevents.1712597849.605934e206d9.368.59 (deflated 75%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_size/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_size/events.out.tfevents.1712597849.605934e206d9.368.66 (deflated 80%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r ff_filters.zip ff_filters\n",
        "#!zip -r ff_filters_errors.zip ff_filters_errors\n",
        "#!zip -r ff_diffs.zip ff_diffs\n",
        "#!zip -r ff_diffs_errors.zip ff_diffs_errors\n",
        "#!zip -r cnn1d_no_filters.zip cnn1d_no_filters\n",
        "#!zip -r cnn1d_no_diffs.zip cnn1d_no_diffs\n",
        "#!zip -r cnn1d_with_filters.zip cnn1d_with_filters\n",
        "#!zip -r cnn1d_with_diffs.zip cnn1d_with_diffs\n",
        "#!zip -r cnn1d_stack_filters.zip cnn1d_stack_filters\n",
        "#!zip -r cnn1d_stack_diffs.zip cnn1d_stack_diffs\n",
        "!zip -r cnn2d_filters.zip cnn2d_filters\n",
        "!zip -r cnn2d_diffs.zip cnn2d_diffs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "4wbuAKbR355x",
        "outputId": "2614302a-fcdb-4351-c27e-528fff89f227"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_061163e7-6b64-481b-87e0-142f9918a915\", \"ff_filters.zip\", 122730)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_772a90be-94de-402b-917e-8fd2874574b1\", \"cnn2d_filters.zip\", 100050)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_14b82663-936d-4967-b774-8aa5bfc456e7\", \"cnn2d_diffs.zip\", 127066)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"ff_filters.zip\")\n",
        "#files.download(\"ff_filters_errors.zip\")\n",
        "#files.download(\"ff_diffs.zip\")\n",
        "#files.download(\"ff_diffs_errors.zip\")\n",
        "#files.download(\"cnn1d_no_filters.zip\")\n",
        "#files.download(\"cnn1d_no_diffs.zip\")\n",
        "#files.download(\"cnn1d_with_filters.zip\")\n",
        "#files.download(\"cnn1d_with_diffs.zip\")\n",
        "#files.download(\"cnn1d_stack_filters.zip\")\n",
        "#files.download(\"cnn1d_stack_diffs.zip\")\n",
        "files.download(\"cnn2d_filters.zip\")\n",
        "files.download(\"cnn2d_diffs.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atlQEfGddz11",
        "outputId": "18a59ad1-b08a-4464-a7d0-fe0b72d27887"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  ff_diffs.zip\n",
            "   creating: ff_diffs/\n",
            "   creating: ff_diffs/lightning_logs/\n",
            "   creating: ff_diffs/lightning_logs/version_0/\n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_median/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_median/events.out.tfevents.1712571718.5987425793bc.2443.70  \n",
            "   creating: ff_diffs/lightning_logs/version_0/losses_training_loss/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/losses_training_loss/events.out.tfevents.1712571718.5987425793bc.2443.67  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_max/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_max/events.out.tfevents.1712571718.5987425793bc.2443.72  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_std/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_std/events.out.tfevents.1712571717.5987425793bc.2443.65  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_min/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_min/events.out.tfevents.1712571718.5987425793bc.2443.68  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_mean/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_mean/events.out.tfevents.1712571717.5987425793bc.2443.64  \n",
            "  inflating: ff_diffs/lightning_logs/version_0/events.out.tfevents.1712571717.5987425793bc.2443.57  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_mean/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_mean/events.out.tfevents.1712571984.5987425793bc.2443.81  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_median/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_median/events.out.tfevents.1712571984.5987425793bc.2443.78  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_std/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_std/events.out.tfevents.1712571718.5987425793bc.2443.74  \n",
            "   creating: ff_diffs/lightning_logs/version_0/losses_validation_loss/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/losses_validation_loss/events.out.tfevents.1712571717.5987425793bc.2443.58  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_median/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_median/events.out.tfevents.1712571717.5987425793bc.2443.61  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_std/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_std/events.out.tfevents.1712571984.5987425793bc.2443.82  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_size/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_size/events.out.tfevents.1712571984.5987425793bc.2443.83  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_mean/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_mean/events.out.tfevents.1712571718.5987425793bc.2443.73  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_size/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_size/events.out.tfevents.1712571718.5987425793bc.2443.75  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_max/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_max/events.out.tfevents.1712571717.5987425793bc.2443.63  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_min/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_min/events.out.tfevents.1712571717.5987425793bc.2443.59  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_q3/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_q3/events.out.tfevents.1712571984.5987425793bc.2443.79  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_q1/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_q1/events.out.tfevents.1712571984.5987425793bc.2443.77  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_size/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_size/events.out.tfevents.1712571717.5987425793bc.2443.66  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_q1/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_q1/events.out.tfevents.1712571718.5987425793bc.2443.69  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q1/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q1/events.out.tfevents.1712571717.5987425793bc.2443.60  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_q3/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_q3/events.out.tfevents.1712571718.5987425793bc.2443.71  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q3/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q3/events.out.tfevents.1712571717.5987425793bc.2443.62  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_min/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_min/events.out.tfevents.1712571984.5987425793bc.2443.76  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_max/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_max/events.out.tfevents.1712571984.5987425793bc.2443.80  \n",
            "Archive:  ff_diffs_errors.zip\n",
            "   creating: ff_diffs_errors/\n",
            "   creating: ff_diffs_errors/lightning_logs/\n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/\n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_median/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_median/events.out.tfevents.1712571986.5987425793bc.2443.98  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/losses_training_loss/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/losses_training_loss/events.out.tfevents.1712571986.5987425793bc.2443.95  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_max/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_max/events.out.tfevents.1712571986.5987425793bc.2443.100  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_std/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_std/events.out.tfevents.1712571985.5987425793bc.2443.93  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_min/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_min/events.out.tfevents.1712571986.5987425793bc.2443.96  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_mean/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_mean/events.out.tfevents.1712571985.5987425793bc.2443.92  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_mean/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_mean/events.out.tfevents.1712572258.5987425793bc.2443.109  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_median/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_median/events.out.tfevents.1712572258.5987425793bc.2443.106  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_std/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_std/events.out.tfevents.1712571986.5987425793bc.2443.102  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/losses_validation_loss/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/losses_validation_loss/events.out.tfevents.1712571985.5987425793bc.2443.86  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_median/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_median/events.out.tfevents.1712571985.5987425793bc.2443.89  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_std/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_std/events.out.tfevents.1712572258.5987425793bc.2443.110  \n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/events.out.tfevents.1712571985.5987425793bc.2443.85  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_size/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_size/events.out.tfevents.1712572258.5987425793bc.2443.111  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_mean/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_mean/events.out.tfevents.1712571986.5987425793bc.2443.101  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_size/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_size/events.out.tfevents.1712571986.5987425793bc.2443.103  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_max/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_max/events.out.tfevents.1712571985.5987425793bc.2443.91  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_min/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_min/events.out.tfevents.1712571985.5987425793bc.2443.87  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_q3/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_q3/events.out.tfevents.1712572258.5987425793bc.2443.107  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_q1/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_q1/events.out.tfevents.1712572258.5987425793bc.2443.105  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_size/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_size/events.out.tfevents.1712571985.5987425793bc.2443.94  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_q1/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_q1/events.out.tfevents.1712571986.5987425793bc.2443.97  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_q1/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_q1/events.out.tfevents.1712571985.5987425793bc.2443.88  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_q3/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_q3/events.out.tfevents.1712571986.5987425793bc.2443.99  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_q3/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_q3/events.out.tfevents.1712571985.5987425793bc.2443.90  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_min/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_min/events.out.tfevents.1712572258.5987425793bc.2443.104  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_max/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_max/events.out.tfevents.1712572258.5987425793bc.2443.108  \n",
            "Archive:  cnn1d_no_filters.zip\n",
            "   creating: cnn1d_no_filters/\n",
            "   creating: cnn1d_no_filters/lightning_logs/\n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/\n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_median/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_median/events.out.tfevents.1712572260.5987425793bc.2443.126  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/losses_training_loss/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/losses_training_loss/events.out.tfevents.1712572260.5987425793bc.2443.123  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_max/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_max/events.out.tfevents.1712572260.5987425793bc.2443.128  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_std/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_std/events.out.tfevents.1712572259.5987425793bc.2443.121  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_min/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_min/events.out.tfevents.1712572260.5987425793bc.2443.124  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_mean/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_mean/events.out.tfevents.1712572258.5987425793bc.2443.120  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_mean/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_mean/events.out.tfevents.1712572585.5987425793bc.2443.137  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_median/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_median/events.out.tfevents.1712572585.5987425793bc.2443.134  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_std/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_std/events.out.tfevents.1712572260.5987425793bc.2443.130  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/losses_validation_loss/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/losses_validation_loss/events.out.tfevents.1712572258.5987425793bc.2443.114  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_median/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_median/events.out.tfevents.1712572258.5987425793bc.2443.117  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_std/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_std/events.out.tfevents.1712572585.5987425793bc.2443.138  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_size/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_size/events.out.tfevents.1712572585.5987425793bc.2443.139  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_mean/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_mean/events.out.tfevents.1712572260.5987425793bc.2443.129  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_size/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_size/events.out.tfevents.1712572260.5987425793bc.2443.131  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_max/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_max/events.out.tfevents.1712572258.5987425793bc.2443.119  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_min/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_min/events.out.tfevents.1712572258.5987425793bc.2443.115  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_q3/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_q3/events.out.tfevents.1712572585.5987425793bc.2443.135  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_q1/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_q1/events.out.tfevents.1712572585.5987425793bc.2443.133  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_size/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_size/events.out.tfevents.1712572259.5987425793bc.2443.122  \n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/events.out.tfevents.1712572258.5987425793bc.2443.113  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_q1/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_q1/events.out.tfevents.1712572260.5987425793bc.2443.125  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_q1/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_q1/events.out.tfevents.1712572258.5987425793bc.2443.116  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_q3/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_q3/events.out.tfevents.1712572260.5987425793bc.2443.127  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_q3/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_q3/events.out.tfevents.1712572258.5987425793bc.2443.118  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_min/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_min/events.out.tfevents.1712572585.5987425793bc.2443.132  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_max/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_max/events.out.tfevents.1712572585.5987425793bc.2443.136  \n",
            "Archive:  cnn1d_no_diffs.zip\n",
            "   creating: cnn1d_no_diffs/\n",
            "   creating: cnn1d_no_diffs/lightning_logs/\n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/\n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_median/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_median/events.out.tfevents.1712572587.5987425793bc.2443.154  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/losses_training_loss/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/losses_training_loss/events.out.tfevents.1712572587.5987425793bc.2443.151  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_max/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_max/events.out.tfevents.1712572587.5987425793bc.2443.156  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_std/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_std/events.out.tfevents.1712572586.5987425793bc.2443.149  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_min/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_min/events.out.tfevents.1712572587.5987425793bc.2443.152  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_mean/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_mean/events.out.tfevents.1712572586.5987425793bc.2443.148  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_mean/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_mean/events.out.tfevents.1712572917.5987425793bc.2443.165  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_median/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_median/events.out.tfevents.1712572917.5987425793bc.2443.162  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_std/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_std/events.out.tfevents.1712572587.5987425793bc.2443.158  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/losses_validation_loss/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/losses_validation_loss/events.out.tfevents.1712572586.5987425793bc.2443.142  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_median/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_median/events.out.tfevents.1712572586.5987425793bc.2443.145  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_std/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_std/events.out.tfevents.1712572917.5987425793bc.2443.166  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_size/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_size/events.out.tfevents.1712572917.5987425793bc.2443.167  \n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/events.out.tfevents.1712572586.5987425793bc.2443.141  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_mean/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_mean/events.out.tfevents.1712572587.5987425793bc.2443.157  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_size/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_size/events.out.tfevents.1712572587.5987425793bc.2443.159  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_max/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_max/events.out.tfevents.1712572586.5987425793bc.2443.147  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_min/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_min/events.out.tfevents.1712572586.5987425793bc.2443.143  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_q3/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_q3/events.out.tfevents.1712572917.5987425793bc.2443.163  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_q1/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_q1/events.out.tfevents.1712572917.5987425793bc.2443.161  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_size/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_size/events.out.tfevents.1712572586.5987425793bc.2443.150  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_q1/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_q1/events.out.tfevents.1712572587.5987425793bc.2443.153  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q1/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q1/events.out.tfevents.1712572586.5987425793bc.2443.144  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_q3/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_q3/events.out.tfevents.1712572587.5987425793bc.2443.155  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q3/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q3/events.out.tfevents.1712572586.5987425793bc.2443.146  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_min/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_min/events.out.tfevents.1712572917.5987425793bc.2443.160  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_max/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_max/events.out.tfevents.1712572917.5987425793bc.2443.164  \n",
            "Archive:  cnn1d_with_filters.zip\n",
            "   creating: cnn1d_with_filters/\n",
            "   creating: cnn1d_with_filters/lightning_logs/\n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/\n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_median/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_median/events.out.tfevents.1712572919.5987425793bc.2443.182  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/losses_training_loss/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/losses_training_loss/events.out.tfevents.1712572919.5987425793bc.2443.179  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_max/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_max/events.out.tfevents.1712572919.5987425793bc.2443.184  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_std/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_std/events.out.tfevents.1712572917.5987425793bc.2443.177  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_min/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_min/events.out.tfevents.1712572919.5987425793bc.2443.180  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_mean/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_mean/events.out.tfevents.1712572917.5987425793bc.2443.176  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_mean/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_mean/events.out.tfevents.1712573265.5987425793bc.2443.193  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_median/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_median/events.out.tfevents.1712573265.5987425793bc.2443.190  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_std/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_std/events.out.tfevents.1712572919.5987425793bc.2443.186  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/losses_validation_loss/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/losses_validation_loss/events.out.tfevents.1712572917.5987425793bc.2443.170  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_median/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_median/events.out.tfevents.1712572917.5987425793bc.2443.173  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_std/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_std/events.out.tfevents.1712573265.5987425793bc.2443.194  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_size/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_size/events.out.tfevents.1712573265.5987425793bc.2443.195  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_mean/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_mean/events.out.tfevents.1712572919.5987425793bc.2443.185  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_size/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_size/events.out.tfevents.1712572919.5987425793bc.2443.187  \n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/events.out.tfevents.1712572917.5987425793bc.2443.169  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_max/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_max/events.out.tfevents.1712572917.5987425793bc.2443.175  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_min/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_min/events.out.tfevents.1712572917.5987425793bc.2443.171  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_q3/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_q3/events.out.tfevents.1712573265.5987425793bc.2443.191  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_q1/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_q1/events.out.tfevents.1712573265.5987425793bc.2443.189  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_size/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_size/events.out.tfevents.1712572917.5987425793bc.2443.178  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_q1/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_q1/events.out.tfevents.1712572919.5987425793bc.2443.181  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_q1/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_q1/events.out.tfevents.1712572917.5987425793bc.2443.172  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_q3/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_q3/events.out.tfevents.1712572919.5987425793bc.2443.183  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_q3/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_q3/events.out.tfevents.1712572917.5987425793bc.2443.174  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_min/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_min/events.out.tfevents.1712573265.5987425793bc.2443.188  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_max/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_max/events.out.tfevents.1712573265.5987425793bc.2443.192  \n",
            "Archive:  cnn1d_with_diffs.zip\n",
            "   creating: cnn1d_with_diffs/\n",
            "   creating: cnn1d_with_diffs/lightning_logs/\n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/events.out.tfevents.1712573266.5987425793bc.2443.197  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_median/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_median/events.out.tfevents.1712573267.5987425793bc.2443.210  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/losses_training_loss/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/losses_training_loss/events.out.tfevents.1712573267.5987425793bc.2443.207  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_max/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_max/events.out.tfevents.1712573267.5987425793bc.2443.212  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_std/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_std/events.out.tfevents.1712573266.5987425793bc.2443.205  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_min/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_min/events.out.tfevents.1712573267.5987425793bc.2443.208  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_mean/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_mean/events.out.tfevents.1712573266.5987425793bc.2443.204  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_mean/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_mean/events.out.tfevents.1712573615.5987425793bc.2443.221  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_median/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_median/events.out.tfevents.1712573615.5987425793bc.2443.218  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_std/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_std/events.out.tfevents.1712573267.5987425793bc.2443.214  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/losses_validation_loss/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/losses_validation_loss/events.out.tfevents.1712573266.5987425793bc.2443.198  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_median/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_median/events.out.tfevents.1712573266.5987425793bc.2443.201  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_std/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_std/events.out.tfevents.1712573615.5987425793bc.2443.222  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_size/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_size/events.out.tfevents.1712573615.5987425793bc.2443.223  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_mean/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_mean/events.out.tfevents.1712573267.5987425793bc.2443.213  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_size/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_size/events.out.tfevents.1712573267.5987425793bc.2443.215  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_max/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_max/events.out.tfevents.1712573266.5987425793bc.2443.203  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_min/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_min/events.out.tfevents.1712573266.5987425793bc.2443.199  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_q3/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_q3/events.out.tfevents.1712573615.5987425793bc.2443.219  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_q1/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_q1/events.out.tfevents.1712573615.5987425793bc.2443.217  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_size/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_size/events.out.tfevents.1712573266.5987425793bc.2443.206  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_q1/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_q1/events.out.tfevents.1712573267.5987425793bc.2443.209  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q1/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q1/events.out.tfevents.1712573266.5987425793bc.2443.200  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_q3/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_q3/events.out.tfevents.1712573267.5987425793bc.2443.211  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q3/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q3/events.out.tfevents.1712573266.5987425793bc.2443.202  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_min/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_min/events.out.tfevents.1712573615.5987425793bc.2443.216  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_max/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_max/events.out.tfevents.1712573615.5987425793bc.2443.220  \n",
            "Archive:  cnn1d_stack_filters.zip\n",
            "   creating: cnn1d_stack_filters/\n",
            "   creating: cnn1d_stack_filters/lightning_logs/\n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/\n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_median/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_median/events.out.tfevents.1712573617.5987425793bc.2443.238  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/losses_training_loss/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/losses_training_loss/events.out.tfevents.1712573617.5987425793bc.2443.235  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_max/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_max/events.out.tfevents.1712573617.5987425793bc.2443.240  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_std/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_std/events.out.tfevents.1712573616.5987425793bc.2443.233  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_min/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_min/events.out.tfevents.1712573617.5987425793bc.2443.236  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_mean/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_mean/events.out.tfevents.1712573616.5987425793bc.2443.232  \n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/events.out.tfevents.1712573616.5987425793bc.2443.225  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_mean/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_mean/events.out.tfevents.1712573967.5987425793bc.2443.249  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_median/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_median/events.out.tfevents.1712573967.5987425793bc.2443.246  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_std/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_std/events.out.tfevents.1712573617.5987425793bc.2443.242  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/losses_validation_loss/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/losses_validation_loss/events.out.tfevents.1712573616.5987425793bc.2443.226  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_median/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_median/events.out.tfevents.1712573616.5987425793bc.2443.229  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_std/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_std/events.out.tfevents.1712573967.5987425793bc.2443.250  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_size/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_size/events.out.tfevents.1712573967.5987425793bc.2443.251  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_mean/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_mean/events.out.tfevents.1712573617.5987425793bc.2443.241  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_size/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_size/events.out.tfevents.1712573617.5987425793bc.2443.243  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_max/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_max/events.out.tfevents.1712573616.5987425793bc.2443.231  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_min/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_min/events.out.tfevents.1712573616.5987425793bc.2443.227  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_q3/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_q3/events.out.tfevents.1712573967.5987425793bc.2443.247  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_q1/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_q1/events.out.tfevents.1712573967.5987425793bc.2443.245  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_size/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_size/events.out.tfevents.1712573616.5987425793bc.2443.234  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_q1/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_q1/events.out.tfevents.1712573617.5987425793bc.2443.237  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_q1/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_q1/events.out.tfevents.1712573616.5987425793bc.2443.228  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_q3/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_q3/events.out.tfevents.1712573617.5987425793bc.2443.239  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_q3/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_q3/events.out.tfevents.1712573616.5987425793bc.2443.230  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_min/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_min/events.out.tfevents.1712573967.5987425793bc.2443.244  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_max/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_max/events.out.tfevents.1712573967.5987425793bc.2443.248  \n",
            "Archive:  cnn1d_stack_diffs.zip\n",
            "   creating: cnn1d_stack_diffs/\n",
            "   creating: cnn1d_stack_diffs/lightning_logs/\n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/\n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_median/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_median/events.out.tfevents.1712573969.5987425793bc.2443.266  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/losses_training_loss/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/losses_training_loss/events.out.tfevents.1712573969.5987425793bc.2443.263  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_max/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_max/events.out.tfevents.1712573969.5987425793bc.2443.268  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_std/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_std/events.out.tfevents.1712573968.5987425793bc.2443.261  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_min/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_min/events.out.tfevents.1712573969.5987425793bc.2443.264  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_mean/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_mean/events.out.tfevents.1712573968.5987425793bc.2443.260  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_mean/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_mean/events.out.tfevents.1712574317.5987425793bc.2443.277  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_median/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_median/events.out.tfevents.1712574317.5987425793bc.2443.274  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_std/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_std/events.out.tfevents.1712573969.5987425793bc.2443.270  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/losses_validation_loss/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/losses_validation_loss/events.out.tfevents.1712573968.5987425793bc.2443.254  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_median/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_median/events.out.tfevents.1712573968.5987425793bc.2443.257  \n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/events.out.tfevents.1712573968.5987425793bc.2443.253  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_std/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_std/events.out.tfevents.1712574317.5987425793bc.2443.278  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_size/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_size/events.out.tfevents.1712574317.5987425793bc.2443.279  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_mean/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_mean/events.out.tfevents.1712573969.5987425793bc.2443.269  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_size/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_size/events.out.tfevents.1712573969.5987425793bc.2443.271  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_max/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_max/events.out.tfevents.1712573968.5987425793bc.2443.259  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_min/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_min/events.out.tfevents.1712573968.5987425793bc.2443.255  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_q3/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_q3/events.out.tfevents.1712574317.5987425793bc.2443.275  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_q1/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_q1/events.out.tfevents.1712574317.5987425793bc.2443.273  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_size/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_size/events.out.tfevents.1712573968.5987425793bc.2443.262  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_q1/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_q1/events.out.tfevents.1712573969.5987425793bc.2443.265  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q1/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q1/events.out.tfevents.1712573968.5987425793bc.2443.256  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_q3/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_q3/events.out.tfevents.1712573969.5987425793bc.2443.267  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q3/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q3/events.out.tfevents.1712573968.5987425793bc.2443.258  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_min/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_min/events.out.tfevents.1712574317.5987425793bc.2443.272  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_max/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_max/events.out.tfevents.1712574317.5987425793bc.2443.276  \n"
          ]
        }
      ],
      "source": [
        "#!unzip ff_filters_errors.zip\n",
        "!unzip ff_diffs.zip\n",
        "!unzip ff_diffs_errors.zip\n",
        "!unzip cnn1d_no_filters.zip\n",
        "!unzip cnn1d_no_diffs.zip\n",
        "!unzip cnn1d_with_filters.zip\n",
        "!unzip cnn1d_with_diffs.zip\n",
        "!unzip cnn1d_stack_filters.zip\n",
        "!unzip cnn1d_stack_diffs.zip"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
