{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install lightning\n",
    "%pip install optuna\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'custom-pytorch-lightning-module'...\n",
      "remote: Enumerating objects: 25, done.\u001b[K\n",
      "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
      "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
      "remote: Total 25 (delta 11), reused 14 (delta 6), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (25/25), 20.01 KiB | 853.00 KiB/s, done.\n",
      "Cloning into 'pytorch-blocks'...\n",
      "remote: Enumerating objects: 11, done.\u001b[K\n",
      "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
      "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
      "remote: Total 11 (delta 3), reused 6 (delta 2), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (11/11), 17.19 KiB | 1.01 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/lucas-battisti/custom-pytorch-lightning-module.git\n",
    "!mv \"custom-pytorch-lightning-module/modules.py\" \"modules.py\"\n",
    "!rm -rf \"custom-pytorch-lightning-module\"\n",
    "\n",
    "!git clone https://github.com/lucas-battisti/pytorch-blocks.git\n",
    "!mv \"pytorch-blocks/blocks.py\" \"blocks.py\"\n",
    "!rm -rf \"pytorch-blocks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "\n",
    "from modules import RegressionModule as Reg\n",
    "from blocks import LinearBlock, Conv1dBlock\n",
    "from data import Custom_DataModule, CNN1D_Dataset\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv(\"data/Dataframe_f.csv\", index_col=0).astype('float32')\n",
    "e = pd.read_csv(\"data/Dataframe_e_f.csv\", index_col=0).astype('float32')\n",
    "z = pd.read_csv(\"data/Dataframe_z.csv\", index_col=0).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def default_training():\n",
    "    L_IN = 16\n",
    "    C_IN = 1\n",
    "    \n",
    "    dm = Custom_DataModule(xez = (x, e, z),\n",
    "                           dataset_class=CNN1D_Dataset,\n",
    "                           version='no', norm=False,\n",
    "                           batch_size=200, num_workers=1)\n",
    "    \n",
    "    convblock1 = Conv1dBlock(in_channels=C_IN, out_channels=32,\n",
    "                             kernel_size=3,\n",
    "                             activation_function=nn.ReLU,\n",
    "                             pooling_layer=nn.MaxPool1d,\n",
    "                             pooling_layer_args={\"kernel_size\": 2})\n",
    "    \n",
    "    L_convblock1 = convblock1.output_shape(L_IN)['L_out']\n",
    "    \n",
    "    convblock2 = Conv1dBlock(in_channels=32, out_channels=64,\n",
    "                             kernel_size=2,\n",
    "                             activation_function=nn.ReLU,\n",
    "                             pooling_layer=nn.MaxPool1d,\n",
    "                             pooling_layer_args={\"kernel_size\": 2})\n",
    "    \n",
    "    L_convblock2 = convblock2.output_shape(L_convblock1)['L_out']\n",
    "    \n",
    "    dense_input = L_convblock2*64\n",
    "    dense_intermed = int(dense_input*0.75)\n",
    "    \n",
    "    l1 = LinearBlock(in_features=dense_input, out_features=dense_intermed,\n",
    "                     activation_function=nn.ReLU)\n",
    "    \n",
    "    l2 = LinearBlock(in_features=dense_intermed, out_features=dense_intermed,\n",
    "                     activation_function=nn.ReLU)\n",
    "    \n",
    "    l3 = LinearBlock(in_features=dense_intermed, out_features=1)\n",
    "    \n",
    "    sequential = nn.Sequential(convblock1,\n",
    "                               convblock2,\n",
    "                               nn.Flatten(start_dim=1, end_dim=2),\n",
    "                               l1,\n",
    "                               l2,\n",
    "                               l3)\n",
    "    \n",
    "    m = Reg(pytorch_module=sequential,\n",
    "            loss_func=nn.MSELoss,\n",
    "            optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3})\n",
    "    \n",
    "    return m, dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCH = 10\n",
    "\n",
    "m, dm = default_training()\n",
    "\n",
    "trainer = L.Trainer(max_epochs=NUM_EPOCH,\n",
    "                        enable_progress_bar = False, log_every_n_steps=1,\n",
    "                        accelerator=\"auto\", devices=1,\n",
    "                        logger = True)\n",
    "trainer.fit(m, datamodule=dm)\n",
    "trainer.test(m, datamodule=dm)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Acnodnem-Ailiram",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
