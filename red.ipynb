{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4RB7GVHUjKG",
        "outputId": "1dcc7926-c601-465c-ff3e-181ddaa006b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'custom-pytorch-lightning-module'...\n",
            "remote: Enumerating objects: 46, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 46 (delta 25), reused 28 (delta 13), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (46/46), 22.47 KiB | 1000.00 KiB/s, done.\n",
            "Resolving deltas: 100% (25/25), done.\n",
            "Cloning into 'pytorch-blocks'...\n",
            "remote: Enumerating objects: 29, done.\u001b[K\n",
            "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 29 (delta 15), reused 18 (delta 8), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (29/29), 20.19 KiB | 1.44 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/lucas-battisti/custom-pytorch-lightning-module.git\n",
        "!mv \"custom-pytorch-lightning-module/modules.py\" \"modules.py\"\n",
        "!rm -rf \"custom-pytorch-lightning-module\"\n",
        "\n",
        "\n",
        "\n",
        "!git clone https://github.com/lucas-battisti/pytorch-blocks.git\n",
        "!mv \"pytorch-blocks/blocks.py\" \"blocks.py\"\n",
        "!rm -rf \"pytorch-blocks\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "epjII3SgUjKL"
      },
      "outputs": [],
      "source": [
        "import dt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AGz22PvSUjKL"
      },
      "outputs": [],
      "source": [
        "set_size = [0.6, 0.2, 0.2]\n",
        "\n",
        "dtfr = dt.frame(df = pd.read_csv('data/Dataframe_m.csv', index_col=0).astype('float32'),\n",
        "         set_size=set_size)\n",
        "\n",
        "f = dtfr.features(['f'])['complete']\n",
        "e_f = dtfr.features(['e_f'])['complete']\n",
        "d = dtfr.features(['d'])['complete']\n",
        "e_d = dtfr.features(['e_d'])['complete']\n",
        "\n",
        "z = dtfr.features(['z'])['complete']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "dr = pd.concat([d, f.r_PStotal], axis=1)\n",
        "e_dr = pd.concat([e_d, e_f.e_r_PStotal], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>e_FUVmag.r_PStotal</th>\n",
              "      <th>e_NUVmag.r_PStotal</th>\n",
              "      <th>e_u_PStotal.r_PStotal</th>\n",
              "      <th>e_J0378_PStotal.r_PStotal</th>\n",
              "      <th>e_J0395_PStotal.r_PStotal</th>\n",
              "      <th>e_J0410_PStotal.r_PStotal</th>\n",
              "      <th>e_J0430_PStotal.r_PStotal</th>\n",
              "      <th>e_g_PStotal.r_PStotal</th>\n",
              "      <th>e_J0515_PStotal.r_PStotal</th>\n",
              "      <th>e_r_PStotal.J0660_PStotal</th>\n",
              "      <th>e_r_PStotal.i_PStotal</th>\n",
              "      <th>e_r_PStotal.J0861_PStotal</th>\n",
              "      <th>e_r_PStotal.z_PStotal</th>\n",
              "      <th>e_r_PStotal.W1_MAG</th>\n",
              "      <th>e_r_PStotal.W2_MAG</th>\n",
              "      <th>e_r_PStotal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28259</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.490197</td>\n",
              "      <td>0.361409</td>\n",
              "      <td>0.993860</td>\n",
              "      <td>0.640165</td>\n",
              "      <td>0.844292</td>\n",
              "      <td>0.375754</td>\n",
              "      <td>0.306923</td>\n",
              "      <td>0.277508</td>\n",
              "      <td>0.303546</td>\n",
              "      <td>0.734722</td>\n",
              "      <td>0.386488</td>\n",
              "      <td>0.372091</td>\n",
              "      <td>0.361586</td>\n",
              "      <td>0.170521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12965</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.183357</td>\n",
              "      <td>0.351511</td>\n",
              "      <td>0.755809</td>\n",
              "      <td>0.597174</td>\n",
              "      <td>0.302322</td>\n",
              "      <td>0.177763</td>\n",
              "      <td>0.278909</td>\n",
              "      <td>0.193954</td>\n",
              "      <td>0.162948</td>\n",
              "      <td>0.644754</td>\n",
              "      <td>0.291367</td>\n",
              "      <td>0.197098</td>\n",
              "      <td>0.304877</td>\n",
              "      <td>0.119703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24989</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.153039</td>\n",
              "      <td>0.157399</td>\n",
              "      <td>0.276831</td>\n",
              "      <td>0.168782</td>\n",
              "      <td>0.228273</td>\n",
              "      <td>0.084912</td>\n",
              "      <td>0.125094</td>\n",
              "      <td>0.123400</td>\n",
              "      <td>0.080169</td>\n",
              "      <td>0.189234</td>\n",
              "      <td>0.104034</td>\n",
              "      <td>0.061918</td>\n",
              "      <td>0.065653</td>\n",
              "      <td>0.059425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11379</th>\n",
              "      <td>0.097136</td>\n",
              "      <td>0.066666</td>\n",
              "      <td>0.094493</td>\n",
              "      <td>0.112013</td>\n",
              "      <td>0.183674</td>\n",
              "      <td>0.160850</td>\n",
              "      <td>0.124598</td>\n",
              "      <td>0.058675</td>\n",
              "      <td>0.089457</td>\n",
              "      <td>0.059825</td>\n",
              "      <td>0.059668</td>\n",
              "      <td>0.097890</td>\n",
              "      <td>0.082528</td>\n",
              "      <td>0.043654</td>\n",
              "      <td>0.048713</td>\n",
              "      <td>0.039369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13164</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.132512</td>\n",
              "      <td>0.137313</td>\n",
              "      <td>0.285285</td>\n",
              "      <td>0.199404</td>\n",
              "      <td>0.209952</td>\n",
              "      <td>0.105783</td>\n",
              "      <td>0.175410</td>\n",
              "      <td>0.108966</td>\n",
              "      <td>0.107785</td>\n",
              "      <td>0.182906</td>\n",
              "      <td>0.167269</td>\n",
              "      <td>0.087590</td>\n",
              "      <td>0.097326</td>\n",
              "      <td>0.068784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14696</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.335437</td>\n",
              "      <td>0.312639</td>\n",
              "      <td>0.322101</td>\n",
              "      <td>0.321018</td>\n",
              "      <td>0.270050</td>\n",
              "      <td>0.114710</td>\n",
              "      <td>0.226655</td>\n",
              "      <td>0.137495</td>\n",
              "      <td>0.119470</td>\n",
              "      <td>0.206916</td>\n",
              "      <td>0.218188</td>\n",
              "      <td>0.088293</td>\n",
              "      <td>0.112312</td>\n",
              "      <td>0.077654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15035</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.454188</td>\n",
              "      <td>0.367730</td>\n",
              "      <td>22.031746</td>\n",
              "      <td>3.486004</td>\n",
              "      <td>3.058647</td>\n",
              "      <td>0.670485</td>\n",
              "      <td>0.246134</td>\n",
              "      <td>0.280563</td>\n",
              "      <td>0.264946</td>\n",
              "      <td>0.248355</td>\n",
              "      <td>0.467746</td>\n",
              "      <td>0.307634</td>\n",
              "      <td>0.165099</td>\n",
              "      <td>0.181725</td>\n",
              "      <td>0.153395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27410</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.220416</td>\n",
              "      <td>0.191300</td>\n",
              "      <td>0.330582</td>\n",
              "      <td>1.113029</td>\n",
              "      <td>0.192757</td>\n",
              "      <td>0.064071</td>\n",
              "      <td>0.113587</td>\n",
              "      <td>0.063508</td>\n",
              "      <td>0.068901</td>\n",
              "      <td>0.109185</td>\n",
              "      <td>0.074335</td>\n",
              "      <td>0.065590</td>\n",
              "      <td>0.068547</td>\n",
              "      <td>0.040842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26975</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.602657</td>\n",
              "      <td>1.673452</td>\n",
              "      <td>2.282888</td>\n",
              "      <td>0.843830</td>\n",
              "      <td>1.682509</td>\n",
              "      <td>0.255705</td>\n",
              "      <td>1.062170</td>\n",
              "      <td>0.278742</td>\n",
              "      <td>0.268491</td>\n",
              "      <td>0.538540</td>\n",
              "      <td>0.374473</td>\n",
              "      <td>0.215756</td>\n",
              "      <td>0.139123</td>\n",
              "      <td>0.133808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17900</th>\n",
              "      <td>0.480288</td>\n",
              "      <td>0.249285</td>\n",
              "      <td>0.090725</td>\n",
              "      <td>0.105765</td>\n",
              "      <td>0.083235</td>\n",
              "      <td>0.134675</td>\n",
              "      <td>0.132750</td>\n",
              "      <td>0.056896</td>\n",
              "      <td>0.082511</td>\n",
              "      <td>0.056248</td>\n",
              "      <td>0.054076</td>\n",
              "      <td>0.086538</td>\n",
              "      <td>0.072848</td>\n",
              "      <td>0.075027</td>\n",
              "      <td>0.101935</td>\n",
              "      <td>0.036491</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29219 rows × 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       e_FUVmag.r_PStotal  e_NUVmag.r_PStotal  e_u_PStotal.r_PStotal  \\\n",
              "28259                 NaN                 NaN               0.490197   \n",
              "12965                 NaN                 NaN               0.183357   \n",
              "24989                 NaN                 NaN               0.153039   \n",
              "11379            0.097136            0.066666               0.094493   \n",
              "13164                 NaN                 NaN               0.132512   \n",
              "...                   ...                 ...                    ...   \n",
              "14696                 NaN                 NaN               0.335437   \n",
              "15035                 NaN            0.454188               0.367730   \n",
              "27410                 NaN                 NaN               0.220416   \n",
              "26975                 NaN                 NaN               0.602657   \n",
              "17900            0.480288            0.249285               0.090725   \n",
              "\n",
              "       e_J0378_PStotal.r_PStotal  e_J0395_PStotal.r_PStotal  \\\n",
              "28259                   0.361409                   0.993860   \n",
              "12965                   0.351511                   0.755809   \n",
              "24989                   0.157399                   0.276831   \n",
              "11379                   0.112013                   0.183674   \n",
              "13164                   0.137313                   0.285285   \n",
              "...                          ...                        ...   \n",
              "14696                   0.312639                   0.322101   \n",
              "15035                  22.031746                   3.486004   \n",
              "27410                   0.191300                   0.330582   \n",
              "26975                   1.673452                   2.282888   \n",
              "17900                   0.105765                   0.083235   \n",
              "\n",
              "       e_J0410_PStotal.r_PStotal  e_J0430_PStotal.r_PStotal  \\\n",
              "28259                   0.640165                   0.844292   \n",
              "12965                   0.597174                   0.302322   \n",
              "24989                   0.168782                   0.228273   \n",
              "11379                   0.160850                   0.124598   \n",
              "13164                   0.199404                   0.209952   \n",
              "...                          ...                        ...   \n",
              "14696                   0.321018                   0.270050   \n",
              "15035                   3.058647                   0.670485   \n",
              "27410                   1.113029                   0.192757   \n",
              "26975                   0.843830                   1.682509   \n",
              "17900                   0.134675                   0.132750   \n",
              "\n",
              "       e_g_PStotal.r_PStotal  e_J0515_PStotal.r_PStotal  \\\n",
              "28259               0.375754                   0.306923   \n",
              "12965               0.177763                   0.278909   \n",
              "24989               0.084912                   0.125094   \n",
              "11379               0.058675                   0.089457   \n",
              "13164               0.105783                   0.175410   \n",
              "...                      ...                        ...   \n",
              "14696               0.114710                   0.226655   \n",
              "15035               0.246134                   0.280563   \n",
              "27410               0.064071                   0.113587   \n",
              "26975               0.255705                   1.062170   \n",
              "17900               0.056896                   0.082511   \n",
              "\n",
              "       e_r_PStotal.J0660_PStotal  e_r_PStotal.i_PStotal  \\\n",
              "28259                   0.277508               0.303546   \n",
              "12965                   0.193954               0.162948   \n",
              "24989                   0.123400               0.080169   \n",
              "11379                   0.059825               0.059668   \n",
              "13164                   0.108966               0.107785   \n",
              "...                          ...                    ...   \n",
              "14696                   0.137495               0.119470   \n",
              "15035                   0.264946               0.248355   \n",
              "27410                   0.063508               0.068901   \n",
              "26975                   0.278742               0.268491   \n",
              "17900                   0.056248               0.054076   \n",
              "\n",
              "       e_r_PStotal.J0861_PStotal  e_r_PStotal.z_PStotal  e_r_PStotal.W1_MAG  \\\n",
              "28259                   0.734722               0.386488            0.372091   \n",
              "12965                   0.644754               0.291367            0.197098   \n",
              "24989                   0.189234               0.104034            0.061918   \n",
              "11379                   0.097890               0.082528            0.043654   \n",
              "13164                   0.182906               0.167269            0.087590   \n",
              "...                          ...                    ...                 ...   \n",
              "14696                   0.206916               0.218188            0.088293   \n",
              "15035                   0.467746               0.307634            0.165099   \n",
              "27410                   0.109185               0.074335            0.065590   \n",
              "26975                   0.538540               0.374473            0.215756   \n",
              "17900                   0.086538               0.072848            0.075027   \n",
              "\n",
              "       e_r_PStotal.W2_MAG  e_r_PStotal  \n",
              "28259            0.361586     0.170521  \n",
              "12965            0.304877     0.119703  \n",
              "24989            0.065653     0.059425  \n",
              "11379            0.048713     0.039369  \n",
              "13164            0.097326     0.068784  \n",
              "...                   ...          ...  \n",
              "14696            0.112312     0.077654  \n",
              "15035            0.181725     0.153395  \n",
              "27410            0.068547     0.040842  \n",
              "26975            0.139123     0.133808  \n",
              "17900            0.101935     0.036491  \n",
              "\n",
              "[29219 rows x 16 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "e_dr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>u_PStotal</th>\n",
              "      <th>J0378_PStotal</th>\n",
              "      <th>J0395_PStotal</th>\n",
              "      <th>J0410_PStotal</th>\n",
              "      <th>J0430_PStotal</th>\n",
              "      <th>g_PStotal</th>\n",
              "      <th>J0515_PStotal</th>\n",
              "      <th>r_PStotal</th>\n",
              "      <th>J0660_PStotal</th>\n",
              "      <th>i_PStotal</th>\n",
              "      <th>J0861_PStotal</th>\n",
              "      <th>z_PStotal</th>\n",
              "      <th>W1_MAG</th>\n",
              "      <th>W2_MAG</th>\n",
              "      <th>FUVmag</th>\n",
              "      <th>NUVmag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28259</th>\n",
              "      <td>22.469261</td>\n",
              "      <td>21.576227</td>\n",
              "      <td>22.345371</td>\n",
              "      <td>21.965141</td>\n",
              "      <td>22.337006</td>\n",
              "      <td>22.554441</td>\n",
              "      <td>21.272848</td>\n",
              "      <td>21.748880</td>\n",
              "      <td>21.916937</td>\n",
              "      <td>21.832203</td>\n",
              "      <td>22.036816</td>\n",
              "      <td>21.438911</td>\n",
              "      <td>18.192154</td>\n",
              "      <td>16.757376</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12965</th>\n",
              "      <td>21.217859</td>\n",
              "      <td>21.732819</td>\n",
              "      <td>22.165600</td>\n",
              "      <td>22.021061</td>\n",
              "      <td>21.212864</td>\n",
              "      <td>21.565050</td>\n",
              "      <td>21.345301</td>\n",
              "      <td>21.317356</td>\n",
              "      <td>21.371239</td>\n",
              "      <td>20.853271</td>\n",
              "      <td>21.729509</td>\n",
              "      <td>21.066626</td>\n",
              "      <td>17.593792</td>\n",
              "      <td>16.775866</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24989</th>\n",
              "      <td>20.277153</td>\n",
              "      <td>19.879484</td>\n",
              "      <td>20.093681</td>\n",
              "      <td>19.628696</td>\n",
              "      <td>20.014717</td>\n",
              "      <td>19.719387</td>\n",
              "      <td>19.465881</td>\n",
              "      <td>19.729364</td>\n",
              "      <td>19.829081</td>\n",
              "      <td>19.370810</td>\n",
              "      <td>19.269211</td>\n",
              "      <td>19.247917</td>\n",
              "      <td>14.885062</td>\n",
              "      <td>14.047417</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11379</th>\n",
              "      <td>20.153725</td>\n",
              "      <td>20.011360</td>\n",
              "      <td>20.088852</td>\n",
              "      <td>20.261497</td>\n",
              "      <td>20.030148</td>\n",
              "      <td>19.867165</td>\n",
              "      <td>19.713602</td>\n",
              "      <td>19.785194</td>\n",
              "      <td>19.923323</td>\n",
              "      <td>19.730227</td>\n",
              "      <td>19.630249</td>\n",
              "      <td>19.639393</td>\n",
              "      <td>15.382491</td>\n",
              "      <td>14.319930</td>\n",
              "      <td>20.154600</td>\n",
              "      <td>19.632500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13164</th>\n",
              "      <td>20.953110</td>\n",
              "      <td>20.506268</td>\n",
              "      <td>21.019735</td>\n",
              "      <td>20.685558</td>\n",
              "      <td>20.791573</td>\n",
              "      <td>20.949329</td>\n",
              "      <td>20.796206</td>\n",
              "      <td>20.650009</td>\n",
              "      <td>20.663494</td>\n",
              "      <td>20.500854</td>\n",
              "      <td>20.256376</td>\n",
              "      <td>20.438744</td>\n",
              "      <td>16.463850</td>\n",
              "      <td>15.293206</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14696</th>\n",
              "      <td>21.850271</td>\n",
              "      <td>21.346283</td>\n",
              "      <td>20.887341</td>\n",
              "      <td>20.901901</td>\n",
              "      <td>20.816593</td>\n",
              "      <td>20.728239</td>\n",
              "      <td>20.831585</td>\n",
              "      <td>20.544155</td>\n",
              "      <td>20.769279</td>\n",
              "      <td>20.320976</td>\n",
              "      <td>20.311724</td>\n",
              "      <td>20.562889</td>\n",
              "      <td>16.120514</td>\n",
              "      <td>15.396585</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15035</th>\n",
              "      <td>22.140581</td>\n",
              "      <td>22.031212</td>\n",
              "      <td>23.689137</td>\n",
              "      <td>23.675552</td>\n",
              "      <td>22.075508</td>\n",
              "      <td>21.966120</td>\n",
              "      <td>21.165073</td>\n",
              "      <td>21.641445</td>\n",
              "      <td>21.859322</td>\n",
              "      <td>21.522324</td>\n",
              "      <td>21.469517</td>\n",
              "      <td>21.150593</td>\n",
              "      <td>16.581169</td>\n",
              "      <td>15.639993</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22.725401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27410</th>\n",
              "      <td>21.220028</td>\n",
              "      <td>20.522636</td>\n",
              "      <td>20.575850</td>\n",
              "      <td>22.214600</td>\n",
              "      <td>20.390205</td>\n",
              "      <td>20.085382</td>\n",
              "      <td>19.886250</td>\n",
              "      <td>19.751108</td>\n",
              "      <td>19.836100</td>\n",
              "      <td>19.748350</td>\n",
              "      <td>19.605396</td>\n",
              "      <td>19.254068</td>\n",
              "      <td>16.125050</td>\n",
              "      <td>14.770831</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26975</th>\n",
              "      <td>22.711790</td>\n",
              "      <td>23.260403</td>\n",
              "      <td>23.183975</td>\n",
              "      <td>22.333622</td>\n",
              "      <td>23.149635</td>\n",
              "      <td>22.274513</td>\n",
              "      <td>22.688931</td>\n",
              "      <td>21.565731</td>\n",
              "      <td>21.937691</td>\n",
              "      <td>21.656973</td>\n",
              "      <td>21.393774</td>\n",
              "      <td>21.368458</td>\n",
              "      <td>17.441290</td>\n",
              "      <td>14.336500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17900</th>\n",
              "      <td>20.238247</td>\n",
              "      <td>19.943356</td>\n",
              "      <td>19.045925</td>\n",
              "      <td>19.789829</td>\n",
              "      <td>19.816391</td>\n",
              "      <td>19.644543</td>\n",
              "      <td>19.412380</td>\n",
              "      <td>19.559959</td>\n",
              "      <td>19.642620</td>\n",
              "      <td>19.414793</td>\n",
              "      <td>19.288475</td>\n",
              "      <td>19.228167</td>\n",
              "      <td>16.531324</td>\n",
              "      <td>15.533143</td>\n",
              "      <td>22.398001</td>\n",
              "      <td>21.415001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29219 rows × 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       u_PStotal  J0378_PStotal  J0395_PStotal  J0410_PStotal  J0430_PStotal  \\\n",
              "28259  22.469261      21.576227      22.345371      21.965141      22.337006   \n",
              "12965  21.217859      21.732819      22.165600      22.021061      21.212864   \n",
              "24989  20.277153      19.879484      20.093681      19.628696      20.014717   \n",
              "11379  20.153725      20.011360      20.088852      20.261497      20.030148   \n",
              "13164  20.953110      20.506268      21.019735      20.685558      20.791573   \n",
              "...          ...            ...            ...            ...            ...   \n",
              "14696  21.850271      21.346283      20.887341      20.901901      20.816593   \n",
              "15035  22.140581      22.031212      23.689137      23.675552      22.075508   \n",
              "27410  21.220028      20.522636      20.575850      22.214600      20.390205   \n",
              "26975  22.711790      23.260403      23.183975      22.333622      23.149635   \n",
              "17900  20.238247      19.943356      19.045925      19.789829      19.816391   \n",
              "\n",
              "       g_PStotal  J0515_PStotal  r_PStotal  J0660_PStotal  i_PStotal  \\\n",
              "28259  22.554441      21.272848  21.748880      21.916937  21.832203   \n",
              "12965  21.565050      21.345301  21.317356      21.371239  20.853271   \n",
              "24989  19.719387      19.465881  19.729364      19.829081  19.370810   \n",
              "11379  19.867165      19.713602  19.785194      19.923323  19.730227   \n",
              "13164  20.949329      20.796206  20.650009      20.663494  20.500854   \n",
              "...          ...            ...        ...            ...        ...   \n",
              "14696  20.728239      20.831585  20.544155      20.769279  20.320976   \n",
              "15035  21.966120      21.165073  21.641445      21.859322  21.522324   \n",
              "27410  20.085382      19.886250  19.751108      19.836100  19.748350   \n",
              "26975  22.274513      22.688931  21.565731      21.937691  21.656973   \n",
              "17900  19.644543      19.412380  19.559959      19.642620  19.414793   \n",
              "\n",
              "       J0861_PStotal  z_PStotal     W1_MAG     W2_MAG     FUVmag     NUVmag  \n",
              "28259      22.036816  21.438911  18.192154  16.757376        NaN        NaN  \n",
              "12965      21.729509  21.066626  17.593792  16.775866        NaN        NaN  \n",
              "24989      19.269211  19.247917  14.885062  14.047417        NaN        NaN  \n",
              "11379      19.630249  19.639393  15.382491  14.319930  20.154600  19.632500  \n",
              "13164      20.256376  20.438744  16.463850  15.293206        NaN        NaN  \n",
              "...              ...        ...        ...        ...        ...        ...  \n",
              "14696      20.311724  20.562889  16.120514  15.396585        NaN        NaN  \n",
              "15035      21.469517  21.150593  16.581169  15.639993        NaN  22.725401  \n",
              "27410      19.605396  19.254068  16.125050  14.770831        NaN        NaN  \n",
              "26975      21.393774  21.368458  17.441290  14.336500        NaN        NaN  \n",
              "17900      19.288475  19.228167  16.531324  15.533143  22.398001  21.415001  \n",
              "\n",
              "[29219 rows x 16 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HUmniuEKUjKM"
      },
      "outputs": [],
      "source": [
        "import lightning as L\n",
        "\n",
        "from modules import RegressionModule as Reg\n",
        "from blocks import LinearBlock, Conv1dBlock, Conv2dBlock\n",
        "from data import FF_Dataset, Custom_DataModule, CNN1D_Dataset, CNN2D_Dataset\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import MaxPool1d, AvgPool1d\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "from math import floor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "I7QCD5oCUjKM"
      },
      "outputs": [],
      "source": [
        "dm = {}\n",
        "m = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2L4YWgh7UjKN"
      },
      "source": [
        "# FF with filters and no errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HU0h2Kf4UjKO",
        "outputId": "40ea1758-d40a-492c-a781-db4f8a4a9485"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: False, used: False\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "WARNING: Missing logger folder: /content/lightning_logs\n",
            "WARNING:lightning.pytorch.loggers.tensorboard:Missing logger folder: /content/lightning_logs\n",
            "INFO: \n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 421   \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "421       Trainable params\n",
            "0         Non-trainable params\n",
            "421       Total params\n",
            "0.002     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 421   \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "421       Trainable params\n",
            "0         Non-trainable params\n",
            "421       Total params\n",
            "0.002     Total estimated model params size (MB)\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=250` reached.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str = 'ff_filters'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (f, None, z),\n",
        "                       dataset_class=FF_Dataset,\n",
        "                       norm=True,\n",
        "                       set_size=set_size,\n",
        "                       batch_size=200, num_workers=1)\n",
        "\n",
        "l1 = LinearBlock(in_features=16, out_features=12,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 12},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=12, out_features=12,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 12},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=12, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=250,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GPFYFJjUjKQ"
      },
      "source": [
        "# FF with filters and errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqRRkyg1UjKQ",
        "outputId": "9909348e-e9f0-4269-e95a-756b8e1847e0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 1.5 K \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "1.5 K     Trainable params\n",
            "0         Non-trainable params\n",
            "1.5 K     Total params\n",
            "0.006     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 1.5 K \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "1.5 K     Trainable params\n",
            "0         Non-trainable params\n",
            "1.5 K     Total params\n",
            "0.006     Total estimated model params size (MB)\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str = 'ff_filters_errors'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (f, e_f, z),\n",
        "                       dataset_class=FF_Dataset,\n",
        "                       norm=True,\n",
        "                       set_size=set_size,\n",
        "                       batch_size=200, num_workers=1)\n",
        "\n",
        "l1 = LinearBlock(in_features=32, out_features=24,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 24},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=24, out_features=24,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 24},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=24, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=250,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOHtZ7pyUjKR"
      },
      "source": [
        "# FF with diffs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCH7erbXUjKR",
        "outputId": "33fe0012-6a58-4b14-bfce-34a0ce1bfe2b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 421   \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "421       Trainable params\n",
            "0         Non-trainable params\n",
            "421       Total params\n",
            "0.002     Total estimated model params size (MB)\n",
            "/home/lucas-battisti/miniconda3/envs/Acnodnem-Ailiram/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/home/lucas-battisti/miniconda3/envs/Acnodnem-Ailiram/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str = 'ff_diffs'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (dr, None, z),\n",
        "                       dataset_class=FF_Dataset,\n",
        "                       norm=True,\n",
        "                       set_size=set_size,\n",
        "                       batch_size=200, num_workers=1)\n",
        "\n",
        "l1 = LinearBlock(in_features=16, out_features=12,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 12},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=12, out_features=12,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 12},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=12, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=250,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkRvbNlVUjKT"
      },
      "source": [
        "# FF with diffs and errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMT1fdvEUjKT",
        "outputId": "c0f8d220-8da6-4c66-de1b-0a7e02a04089"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 1.5 K \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "1.5 K     Trainable params\n",
            "0         Non-trainable params\n",
            "1.5 K     Total params\n",
            "0.006     Total estimated model params size (MB)\n",
            "/home/lucas-battisti/miniconda3/envs/Acnodnem-Ailiram/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "/home/lucas-battisti/miniconda3/envs/Acnodnem-Ailiram/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "`Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/home/lucas-battisti/miniconda3/envs/Acnodnem-Ailiram/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str = 'ff_diffs_errors'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (dr, e_dr, z),\n",
        "                       dataset_class=FF_Dataset,\n",
        "                       norm=True,\n",
        "                       set_size=set_size,\n",
        "                       batch_size=200, num_workers=1)\n",
        "\n",
        "l1 = LinearBlock(in_features=32, out_features=24,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 24},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=24, out_features=24,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 24},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=24, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=250,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yxGFV4fUjKU"
      },
      "source": [
        "# CNN1D_no with filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6MzCRSxUjKU",
        "outputId": "4027079e-8396-4000-bd12-61541f94aa4c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 53.9 K\n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "53.9 K    Trainable params\n",
            "0         Non-trainable params\n",
            "53.9 K    Total params\n",
            "0.215     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 53.9 K\n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "53.9 K    Trainable params\n",
            "0         Non-trainable params\n",
            "53.9 K    Total params\n",
            "0.215     Total estimated model params size (MB)\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str = 'cnn1d_no_filters'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (f, e_f, z),\n",
        "                       dataset_class=CNN1D_Dataset,\n",
        "                       version='no', norm=True,\n",
        "                       set_size=set_size,\n",
        "                       batch_size=200, num_workers=1)\n",
        "\n",
        "c1 = Conv1dBlock(in_channels=1, out_channels=32,\n",
        "                 kernel_size=3,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 32},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "c2 = Conv1dBlock(in_channels=32, out_channels=64,\n",
        "                 kernel_size=2,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 64},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "flatten = nn.Flatten()\n",
        "\n",
        "l1 = LinearBlock(in_features=192, out_features=144,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 144},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=144, out_features=144,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 144},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=144, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(c1, c2, flatten,\n",
        "                           l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=250,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6XRrCBIUjKU"
      },
      "source": [
        "# CNN1D_no with diffs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZEysR5sUjKV",
        "outputId": "0f652dfe-f493-42d1-ba19-886893570a0c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 44.7 K\n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "44.7 K    Trainable params\n",
            "0         Non-trainable params\n",
            "44.7 K    Total params\n",
            "0.179     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 44.7 K\n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "44.7 K    Trainable params\n",
            "0         Non-trainable params\n",
            "44.7 K    Total params\n",
            "0.179     Total estimated model params size (MB)\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str = 'cnn1d_no_diffs'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (d, e_d, z),\n",
        "                       dataset_class=CNN1D_Dataset,\n",
        "                       version='no', norm=True,\n",
        "                       set_size=set_size,\n",
        "                       batch_size=200, num_workers=1)\n",
        "\n",
        "c1 = Conv1dBlock(in_channels=1, out_channels=32,\n",
        "                 kernel_size=3,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 32},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "c2 = Conv1dBlock(in_channels=32, out_channels=64,\n",
        "                 kernel_size=2,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 64},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "flatten = nn.Flatten()\n",
        "\n",
        "l1 = LinearBlock(in_features=128, out_features=144,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 144},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=144, out_features=144,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 144},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=144, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(c1, c2, flatten,\n",
        "                           l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=250,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfamPT7-UjKV"
      },
      "source": [
        "# CNN1D_with with filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSi-_JD9UjKW",
        "outputId": "5364453e-118a-4b54-dbf1-816a22a71f93"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 270 K \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "270 K     Trainable params\n",
            "0         Non-trainable params\n",
            "270 K     Total params\n",
            "1.081     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 270 K \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "270 K     Trainable params\n",
            "0         Non-trainable params\n",
            "270 K     Total params\n",
            "1.081     Total estimated model params size (MB)\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str = 'cnn1d_with_filters'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (f, e_f, z),\n",
        "                       dataset_class=CNN1D_Dataset,\n",
        "                       version='with', norm=True,\n",
        "                       set_size=set_size,\n",
        "                       batch_size=200, num_workers=1)\n",
        "\n",
        "c1 = Conv1dBlock(in_channels=1, out_channels=32,\n",
        "                 kernel_size=3,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 32},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "c2 = Conv1dBlock(in_channels=32, out_channels=64,\n",
        "                 kernel_size=2,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 64},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "flatten = nn.Flatten()\n",
        "\n",
        "l1 = LinearBlock(in_features=448, out_features=336,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 336},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=336, out_features=336,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 336},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=336, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(c1, c2, flatten,\n",
        "                           l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=250,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYlhEzakUjKW"
      },
      "source": [
        "# CNN1D_with with diffs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ovm2BQF-UjKW",
        "outputId": "ad5bba48-3eb5-4c5d-e9e9-ebaca93e48a9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 248 K \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "248 K     Trainable params\n",
            "0         Non-trainable params\n",
            "248 K     Total params\n",
            "0.995     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 248 K \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "248 K     Trainable params\n",
            "0         Non-trainable params\n",
            "248 K     Total params\n",
            "0.995     Total estimated model params size (MB)\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str = 'cnn1d_with_diffs'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (d, e_d, z),\n",
        "                       dataset_class=CNN1D_Dataset,\n",
        "                       version='with', norm=True,\n",
        "                       set_size=set_size,\n",
        "                       batch_size=200, num_workers=1)\n",
        "\n",
        "c1 = Conv1dBlock(in_channels=1, out_channels=32,\n",
        "                 kernel_size=3,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 32},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "c2 = Conv1dBlock(in_channels=32, out_channels=64,\n",
        "                 kernel_size=2,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 64},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "flatten = nn.Flatten()\n",
        "\n",
        "l1 = LinearBlock(in_features=384, out_features=336,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 336},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=336, out_features=336,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 336},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=336, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(c1, c2, flatten,\n",
        "                           l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,max_epochs=250\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=250,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suaAYcQfUjKX"
      },
      "source": [
        "# CNN1D_stack with filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2L7x7jfJUjKX",
        "outputId": "635b3bb3-1d2b-4e2c-e3d1-b6c8942a1b5f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 54.0 K\n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "54.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "54.0 K    Total params\n",
            "0.216     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 54.0 K\n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "54.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "54.0 K    Total params\n",
            "0.216     Total estimated model params size (MB)\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str = 'cnn1d_stack_filters'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (f, e_f, z),\n",
        "                       dataset_class=CNN1D_Dataset,\n",
        "                       version='stack', norm=True,\n",
        "                       set_size=set_size,\n",
        "                       batch_size=200, num_workers=1)\n",
        "\n",
        "c1 = Conv1dBlock(in_channels=2, out_channels=32,\n",
        "                 kernel_size=3,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 32},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "c2 = Conv1dBlock(in_channels=32, out_channels=64,\n",
        "                 kernel_size=2,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 64},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "flatten = nn.Flatten()\n",
        "\n",
        "l1 = LinearBlock(in_features=192, out_features=144,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 144},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=144, out_features=144,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 144},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=144, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(c1, c2, flatten,\n",
        "                           l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=250,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-yDhG1SUjKY"
      },
      "source": [
        "# CNN1D_stack with diffs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AilGuS8CUjKY",
        "outputId": "f54d66ae-7697-4196-bb5a-932e1300bee3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 46.9 K\n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "46.9 K    Trainable params\n",
            "0         Non-trainable params\n",
            "46.9 K    Total params\n",
            "0.187     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 46.9 K\n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "46.9 K    Trainable params\n",
            "0         Non-trainable params\n",
            "46.9 K    Total params\n",
            "0.187     Total estimated model params size (MB)\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str = 'cnn1d_stack_diffs'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (d, e_d, z),\n",
        "                       dataset_class=CNN1D_Dataset,\n",
        "                       version='stack', norm=True,\n",
        "                       set_size=set_size,\n",
        "                       batch_size=200, num_workers=1)\n",
        "\n",
        "c1 = Conv1dBlock(in_channels=2, out_channels=32,\n",
        "                 kernel_size=4,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 32},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "c2 = Conv1dBlock(in_channels=32, out_channels=64,\n",
        "                 kernel_size=3,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 64},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=MaxPool1d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "flatten = nn.Flatten()\n",
        "\n",
        "l1 = LinearBlock(in_features=128, out_features=144,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 144},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=144, out_features=144,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 144},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=144, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(c1, c2, flatten,\n",
        "                           l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=250,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPGIRVW-UjKY"
      },
      "source": [
        "# CNN2D with filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLgl75pxUjKY",
        "outputId": "6078749c-5841-4e2e-a55a-5f6d84b2e325"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: False, used: False\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: \n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 214 K \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "214 K     Trainable params\n",
            "0         Non-trainable params\n",
            "214 K     Total params\n",
            "0.859     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 214 K \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "214 K     Trainable params\n",
            "0         Non-trainable params\n",
            "214 K     Total params\n",
            "0.859     Total estimated model params size (MB)\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=175` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=175` reached.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str = 'cnn2d_filters'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (f, e_f, z),\n",
        "                       dataset_class=CNN2D_Dataset,\n",
        "                       K=20, t_inf=10, t_sup=10, norm=True,\n",
        "                       set_size=set_size,\n",
        "                       batch_size=200, num_workers=1)\n",
        "\n",
        "c1 = Conv2dBlock(in_channels=1, out_channels=32,\n",
        "                 kernel_size=4,\n",
        "                 norm_layer=nn.BatchNorm2d, norm_layer_args={'num_features': 32},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=nn.MaxPool2d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "c2 = Conv2dBlock(in_channels=32, out_channels=64,\n",
        "                 kernel_size=3,\n",
        "                 norm_layer=nn.BatchNorm2d, norm_layer_args={'num_features': 64},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=nn.MaxPool2d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "flatten = nn.Flatten()\n",
        "\n",
        "l1 = LinearBlock(in_features=384, out_features=288,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 288},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=288, out_features=288,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 288},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=288, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(c1, c2, flatten,\n",
        "                           l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=175,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OocjQ0b-UjKZ"
      },
      "source": [
        "# CNN2D with diffs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEFIEFUqUjKZ",
        "outputId": "37df4bf2-474f-418a-af15-d4ed1715a54e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: GPU available: False, used: False\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: \n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 159 K \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "159 K     Trainable params\n",
            "0         Non-trainable params\n",
            "159 K     Total params\n",
            "0.639     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name           | Type       | Params\n",
            "----------------------------------------------\n",
            "0 | pytorch_module | Sequential | 159 K \n",
            "1 | loss_func      | MSELoss    | 0     \n",
            "----------------------------------------------\n",
            "159 K     Trainable params\n",
            "0         Non-trainable params\n",
            "159 K     Total params\n",
            "0.639     Total estimated model params size (MB)\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=250` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=250` reached.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str = 'cnn2d_diffs'\n",
        "\n",
        "dm[str] = Custom_DataModule(xez = (d, e_d, z),\n",
        "                       dataset_class=CNN2D_Dataset,\n",
        "                       K=20, t_inf=10, t_sup=10, norm=True,\n",
        "                       set_size=set_size,\n",
        "                       batch_size=200, num_workers=1)\n",
        "\n",
        "c1 = Conv2dBlock(in_channels=1, out_channels=32,\n",
        "                 kernel_size=5,\n",
        "                 norm_layer=nn.BatchNorm2d, norm_layer_args={'num_features': 32},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=nn.MaxPool2d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "c2 = Conv2dBlock(in_channels=32, out_channels=64,\n",
        "                 kernel_size=3,\n",
        "                 norm_layer=nn.BatchNorm2d, norm_layer_args={'num_features': 64},\n",
        "                 activation_function=nn.ReLU,\n",
        "                 pooling_layer=nn.MaxPool2d, pooling_layer_args=\n",
        "                 {\"kernel_size\": 2})\n",
        "\n",
        "flatten = nn.Flatten()\n",
        "\n",
        "l1 = LinearBlock(in_features=192, out_features=288,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 288},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l2 = LinearBlock(in_features=288, out_features=288,\n",
        "                 norm_layer=nn.BatchNorm1d, norm_layer_args={'num_features': 288},\n",
        "                 activation_function=nn.ReLU)\n",
        "\n",
        "l3 = LinearBlock(in_features=288, out_features=1)\n",
        "\n",
        "sequential = nn.Sequential(c1, c2, flatten,\n",
        "                           l1, l2, l3)\n",
        "\n",
        "m[str] = Reg(pytorch_module=sequential,\n",
        "        loss_func=nn.MSELoss,\n",
        "        optimizer=torch.optim.Adam, optimizer_args={\"lr\": 1e-3},\n",
        "        tb_dir = str)\n",
        "\n",
        "trainer = L.Trainer(max_epochs=250,\n",
        "                        enable_progress_bar = False, log_every_n_steps=1,\n",
        "                        accelerator=\"auto\", devices=1,\n",
        "                        logger = True)\n",
        "\n",
        "trainer.fit(m[str], datamodule=dm[str])\n",
        "trainer.test(m[str], datamodule=dm[str])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eA-6znM63seE",
        "outputId": "c2a43897-c7a7-4bba-9fd2-53e9d8f3f345"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: ff_filters/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_std/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_std/events.out.tfevents.1712597390.605934e206d9.368.26 (deflated 10%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_mean/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_mean/events.out.tfevents.1712597079.605934e206d9.368.17 (deflated 74%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_size/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_size/events.out.tfevents.1712597390.605934e206d9.368.27 (deflated 10%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_median/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_median/events.out.tfevents.1712597077.605934e206d9.368.5 (deflated 76%)\n",
            "  adding: ff_filters/lightning_logs/version_0/losses_validation_loss/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/losses_validation_loss/events.out.tfevents.1712597077.605934e206d9.368.2 (deflated 63%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_min/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_min/events.out.tfevents.1712597390.605934e206d9.368.20 (deflated 10%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_min/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_min/events.out.tfevents.1712597079.605934e206d9.368.12 (deflated 76%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_q3/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_q3/events.out.tfevents.1712597077.605934e206d9.368.6 (deflated 76%)\n",
            "  adding: ff_filters/lightning_logs/version_0/losses_training_loss/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/losses_training_loss/events.out.tfevents.1712597079.605934e206d9.368.11 (deflated 63%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_std/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_std/events.out.tfevents.1712597079.605934e206d9.368.18 (deflated 74%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_max/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_max/events.out.tfevents.1712597390.605934e206d9.368.24 (deflated 10%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_q1/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_q1/events.out.tfevents.1712597390.605934e206d9.368.21 (deflated 10%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_max/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_max/events.out.tfevents.1712597077.605934e206d9.368.7 (deflated 76%)\n",
            "  adding: ff_filters/lightning_logs/version_0/events.out.tfevents.1712597077.605934e206d9.368.1 (deflated 5%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_mean/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_mean/events.out.tfevents.1712597390.605934e206d9.368.25 (deflated 10%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_q1/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_q1/events.out.tfevents.1712597077.605934e206d9.368.4 (deflated 76%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_q3/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_q3/events.out.tfevents.1712597390.605934e206d9.368.23 (deflated 10%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_mean/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_mean/events.out.tfevents.1712597077.605934e206d9.368.8 (deflated 76%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_q3/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_q3/events.out.tfevents.1712597079.605934e206d9.368.15 (deflated 74%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_std/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_std/events.out.tfevents.1712597077.605934e206d9.368.9 (deflated 76%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_q1/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_q1/events.out.tfevents.1712597079.605934e206d9.368.13 (deflated 74%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_size/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_size/events.out.tfevents.1712597079.605934e206d9.368.19 (deflated 79%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_median/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (test)_median/events.out.tfevents.1712597390.605934e206d9.368.22 (deflated 10%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_max/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_max/events.out.tfevents.1712597079.605934e206d9.368.16 (deflated 74%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_median/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (train)_median/events.out.tfevents.1712597079.605934e206d9.368.14 (deflated 74%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_min/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_min/events.out.tfevents.1712597077.605934e206d9.368.3 (deflated 76%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_size/ (stored 0%)\n",
            "  adding: ff_filters/lightning_logs/version_0/squared_errors_stats (validation)_size/events.out.tfevents.1712597077.605934e206d9.368.10 (deflated 81%)\n",
            "  adding: cnn2d_filters/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_std/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_std/events.out.tfevents.1712602014.605934e206d9.368.110 (deflated 9%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_mean/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_mean/events.out.tfevents.1712600262.605934e206d9.368.101 (deflated 72%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_size/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_size/events.out.tfevents.1712602014.605934e206d9.368.111 (deflated 9%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_median/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_median/events.out.tfevents.1712600251.605934e206d9.368.89 (deflated 74%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/losses_validation_loss/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/losses_validation_loss/events.out.tfevents.1712600251.605934e206d9.368.86 (deflated 61%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_min/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_min/events.out.tfevents.1712602014.605934e206d9.368.104 (deflated 9%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_min/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_min/events.out.tfevents.1712600262.605934e206d9.368.96 (deflated 74%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_q3/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_q3/events.out.tfevents.1712600251.605934e206d9.368.90 (deflated 74%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/losses_training_loss/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/losses_training_loss/events.out.tfevents.1712600262.605934e206d9.368.95 (deflated 60%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_std/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_std/events.out.tfevents.1712600262.605934e206d9.368.102 (deflated 72%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_max/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_max/events.out.tfevents.1712602014.605934e206d9.368.108 (deflated 9%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_q1/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_q1/events.out.tfevents.1712602014.605934e206d9.368.105 (deflated 9%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/events.out.tfevents.1712600251.605934e206d9.368.85 (deflated 4%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_max/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_max/events.out.tfevents.1712600251.605934e206d9.368.91 (deflated 74%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_mean/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_mean/events.out.tfevents.1712602014.605934e206d9.368.109 (deflated 9%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_q1/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_q1/events.out.tfevents.1712600251.605934e206d9.368.88 (deflated 74%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_q3/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_q3/events.out.tfevents.1712602014.605934e206d9.368.107 (deflated 9%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_mean/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_mean/events.out.tfevents.1712600251.605934e206d9.368.92 (deflated 74%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_q3/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_q3/events.out.tfevents.1712600262.605934e206d9.368.99 (deflated 72%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_std/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_std/events.out.tfevents.1712600251.605934e206d9.368.93 (deflated 74%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_q1/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_q1/events.out.tfevents.1712600262.605934e206d9.368.97 (deflated 72%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_size/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_size/events.out.tfevents.1712600262.605934e206d9.368.103 (deflated 78%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_median/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (test)_median/events.out.tfevents.1712602014.605934e206d9.368.106 (deflated 9%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_max/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_max/events.out.tfevents.1712600262.605934e206d9.368.100 (deflated 72%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_median/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (train)_median/events.out.tfevents.1712600262.605934e206d9.368.98 (deflated 72%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_min/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_min/events.out.tfevents.1712600251.605934e206d9.368.87 (deflated 74%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_size/ (stored 0%)\n",
            "  adding: cnn2d_filters/lightning_logs/version_0/squared_errors_stats (validation)_size/events.out.tfevents.1712600251.605934e206d9.368.94 (deflated 79%)\n",
            "  adding: cnn2d_diffs/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_std/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_std/events.out.tfevents.1712600249.605934e206d9.368.82 (deflated 10%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_mean/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_mean/events.out.tfevents.1712597858.605934e206d9.368.73 (deflated 73%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_size/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_size/events.out.tfevents.1712600249.605934e206d9.368.83 (deflated 10%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_median/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_median/events.out.tfevents.1712597849.605934e206d9.368.61 (deflated 75%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/losses_validation_loss/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/losses_validation_loss/events.out.tfevents.1712597849.605934e206d9.368.58 (deflated 61%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_min/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_min/events.out.tfevents.1712600249.605934e206d9.368.76 (deflated 10%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_min/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_min/events.out.tfevents.1712597858.605934e206d9.368.68 (deflated 75%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q3/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q3/events.out.tfevents.1712597849.605934e206d9.368.62 (deflated 75%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/losses_training_loss/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/losses_training_loss/events.out.tfevents.1712597858.605934e206d9.368.67 (deflated 61%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_std/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_std/events.out.tfevents.1712597858.605934e206d9.368.74 (deflated 73%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_max/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_max/events.out.tfevents.1712600249.605934e206d9.368.80 (deflated 10%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_q1/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_q1/events.out.tfevents.1712600249.605934e206d9.368.77 (deflated 10%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_max/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_max/events.out.tfevents.1712597849.605934e206d9.368.63 (deflated 75%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_mean/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_mean/events.out.tfevents.1712600249.605934e206d9.368.81 (deflated 10%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q1/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q1/events.out.tfevents.1712597849.605934e206d9.368.60 (deflated 75%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_q3/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_q3/events.out.tfevents.1712600249.605934e206d9.368.79 (deflated 10%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_mean/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_mean/events.out.tfevents.1712597849.605934e206d9.368.64 (deflated 75%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_q3/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_q3/events.out.tfevents.1712597858.605934e206d9.368.71 (deflated 73%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_std/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_std/events.out.tfevents.1712597849.605934e206d9.368.65 (deflated 75%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_q1/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_q1/events.out.tfevents.1712597858.605934e206d9.368.69 (deflated 73%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_size/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_size/events.out.tfevents.1712597858.605934e206d9.368.75 (deflated 78%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_median/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (test)_median/events.out.tfevents.1712600249.605934e206d9.368.78 (deflated 10%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_max/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_max/events.out.tfevents.1712597858.605934e206d9.368.72 (deflated 73%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/events.out.tfevents.1712597849.605934e206d9.368.57 (deflated 5%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_median/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (train)_median/events.out.tfevents.1712597858.605934e206d9.368.70 (deflated 73%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_min/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_min/events.out.tfevents.1712597849.605934e206d9.368.59 (deflated 75%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_size/ (stored 0%)\n",
            "  adding: cnn2d_diffs/lightning_logs/version_0/squared_errors_stats (validation)_size/events.out.tfevents.1712597849.605934e206d9.368.66 (deflated 80%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r ff_filters.zip ff_filters\n",
        "#!zip -r ff_filters_errors.zip ff_filters_errors\n",
        "#!zip -r ff_diffs.zip ff_diffs\n",
        "#!zip -r ff_diffs_errors.zip ff_diffs_errors\n",
        "#!zip -r cnn1d_no_filters.zip cnn1d_no_filters\n",
        "#!zip -r cnn1d_no_diffs.zip cnn1d_no_diffs\n",
        "#!zip -r cnn1d_with_filters.zip cnn1d_with_filters\n",
        "#!zip -r cnn1d_with_diffs.zip cnn1d_with_diffs\n",
        "#!zip -r cnn1d_stack_filters.zip cnn1d_stack_filters\n",
        "#!zip -r cnn1d_stack_diffs.zip cnn1d_stack_diffs\n",
        "!zip -r cnn2d_filters.zip cnn2d_filters\n",
        "!zip -r cnn2d_diffs.zip cnn2d_diffs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "4wbuAKbR355x",
        "outputId": "2614302a-fcdb-4351-c27e-528fff89f227"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_061163e7-6b64-481b-87e0-142f9918a915\", \"ff_filters.zip\", 122730)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_772a90be-94de-402b-917e-8fd2874574b1\", \"cnn2d_filters.zip\", 100050)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_14b82663-936d-4967-b774-8aa5bfc456e7\", \"cnn2d_diffs.zip\", 127066)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"ff_filters.zip\")\n",
        "#files.download(\"ff_filters_errors.zip\")\n",
        "#files.download(\"ff_diffs.zip\")\n",
        "#files.download(\"ff_diffs_errors.zip\")\n",
        "#files.download(\"cnn1d_no_filters.zip\")\n",
        "#files.download(\"cnn1d_no_diffs.zip\")\n",
        "#files.download(\"cnn1d_with_filters.zip\")\n",
        "#files.download(\"cnn1d_with_diffs.zip\")\n",
        "#files.download(\"cnn1d_stack_filters.zip\")\n",
        "#files.download(\"cnn1d_stack_diffs.zip\")\n",
        "files.download(\"cnn2d_filters.zip\")\n",
        "files.download(\"cnn2d_diffs.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atlQEfGddz11",
        "outputId": "18a59ad1-b08a-4464-a7d0-fe0b72d27887"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  ff_diffs.zip\n",
            "   creating: ff_diffs/\n",
            "   creating: ff_diffs/lightning_logs/\n",
            "   creating: ff_diffs/lightning_logs/version_0/\n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_median/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_median/events.out.tfevents.1712571718.5987425793bc.2443.70  \n",
            "   creating: ff_diffs/lightning_logs/version_0/losses_training_loss/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/losses_training_loss/events.out.tfevents.1712571718.5987425793bc.2443.67  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_max/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_max/events.out.tfevents.1712571718.5987425793bc.2443.72  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_std/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_std/events.out.tfevents.1712571717.5987425793bc.2443.65  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_min/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_min/events.out.tfevents.1712571718.5987425793bc.2443.68  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_mean/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_mean/events.out.tfevents.1712571717.5987425793bc.2443.64  \n",
            "  inflating: ff_diffs/lightning_logs/version_0/events.out.tfevents.1712571717.5987425793bc.2443.57  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_mean/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_mean/events.out.tfevents.1712571984.5987425793bc.2443.81  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_median/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_median/events.out.tfevents.1712571984.5987425793bc.2443.78  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_std/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_std/events.out.tfevents.1712571718.5987425793bc.2443.74  \n",
            "   creating: ff_diffs/lightning_logs/version_0/losses_validation_loss/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/losses_validation_loss/events.out.tfevents.1712571717.5987425793bc.2443.58  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_median/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_median/events.out.tfevents.1712571717.5987425793bc.2443.61  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_std/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_std/events.out.tfevents.1712571984.5987425793bc.2443.82  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_size/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_size/events.out.tfevents.1712571984.5987425793bc.2443.83  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_mean/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_mean/events.out.tfevents.1712571718.5987425793bc.2443.73  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_size/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_size/events.out.tfevents.1712571718.5987425793bc.2443.75  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_max/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_max/events.out.tfevents.1712571717.5987425793bc.2443.63  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_min/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_min/events.out.tfevents.1712571717.5987425793bc.2443.59  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_q3/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_q3/events.out.tfevents.1712571984.5987425793bc.2443.79  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_q1/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_q1/events.out.tfevents.1712571984.5987425793bc.2443.77  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_size/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_size/events.out.tfevents.1712571717.5987425793bc.2443.66  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_q1/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_q1/events.out.tfevents.1712571718.5987425793bc.2443.69  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q1/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q1/events.out.tfevents.1712571717.5987425793bc.2443.60  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_q3/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (train)_q3/events.out.tfevents.1712571718.5987425793bc.2443.71  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q3/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q3/events.out.tfevents.1712571717.5987425793bc.2443.62  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_min/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_min/events.out.tfevents.1712571984.5987425793bc.2443.76  \n",
            "   creating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_max/\n",
            "  inflating: ff_diffs/lightning_logs/version_0/squared_errors_stats (test)_max/events.out.tfevents.1712571984.5987425793bc.2443.80  \n",
            "Archive:  ff_diffs_errors.zip\n",
            "   creating: ff_diffs_errors/\n",
            "   creating: ff_diffs_errors/lightning_logs/\n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/\n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_median/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_median/events.out.tfevents.1712571986.5987425793bc.2443.98  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/losses_training_loss/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/losses_training_loss/events.out.tfevents.1712571986.5987425793bc.2443.95  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_max/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_max/events.out.tfevents.1712571986.5987425793bc.2443.100  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_std/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_std/events.out.tfevents.1712571985.5987425793bc.2443.93  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_min/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_min/events.out.tfevents.1712571986.5987425793bc.2443.96  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_mean/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_mean/events.out.tfevents.1712571985.5987425793bc.2443.92  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_mean/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_mean/events.out.tfevents.1712572258.5987425793bc.2443.109  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_median/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_median/events.out.tfevents.1712572258.5987425793bc.2443.106  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_std/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_std/events.out.tfevents.1712571986.5987425793bc.2443.102  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/losses_validation_loss/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/losses_validation_loss/events.out.tfevents.1712571985.5987425793bc.2443.86  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_median/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_median/events.out.tfevents.1712571985.5987425793bc.2443.89  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_std/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_std/events.out.tfevents.1712572258.5987425793bc.2443.110  \n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/events.out.tfevents.1712571985.5987425793bc.2443.85  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_size/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_size/events.out.tfevents.1712572258.5987425793bc.2443.111  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_mean/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_mean/events.out.tfevents.1712571986.5987425793bc.2443.101  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_size/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_size/events.out.tfevents.1712571986.5987425793bc.2443.103  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_max/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_max/events.out.tfevents.1712571985.5987425793bc.2443.91  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_min/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_min/events.out.tfevents.1712571985.5987425793bc.2443.87  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_q3/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_q3/events.out.tfevents.1712572258.5987425793bc.2443.107  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_q1/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_q1/events.out.tfevents.1712572258.5987425793bc.2443.105  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_size/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_size/events.out.tfevents.1712571985.5987425793bc.2443.94  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_q1/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_q1/events.out.tfevents.1712571986.5987425793bc.2443.97  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_q1/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_q1/events.out.tfevents.1712571985.5987425793bc.2443.88  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_q3/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (train)_q3/events.out.tfevents.1712571986.5987425793bc.2443.99  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_q3/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (validation)_q3/events.out.tfevents.1712571985.5987425793bc.2443.90  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_min/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_min/events.out.tfevents.1712572258.5987425793bc.2443.104  \n",
            "   creating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_max/\n",
            "  inflating: ff_diffs_errors/lightning_logs/version_0/squared_errors_stats (test)_max/events.out.tfevents.1712572258.5987425793bc.2443.108  \n",
            "Archive:  cnn1d_no_filters.zip\n",
            "   creating: cnn1d_no_filters/\n",
            "   creating: cnn1d_no_filters/lightning_logs/\n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/\n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_median/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_median/events.out.tfevents.1712572260.5987425793bc.2443.126  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/losses_training_loss/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/losses_training_loss/events.out.tfevents.1712572260.5987425793bc.2443.123  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_max/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_max/events.out.tfevents.1712572260.5987425793bc.2443.128  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_std/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_std/events.out.tfevents.1712572259.5987425793bc.2443.121  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_min/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_min/events.out.tfevents.1712572260.5987425793bc.2443.124  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_mean/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_mean/events.out.tfevents.1712572258.5987425793bc.2443.120  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_mean/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_mean/events.out.tfevents.1712572585.5987425793bc.2443.137  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_median/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_median/events.out.tfevents.1712572585.5987425793bc.2443.134  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_std/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_std/events.out.tfevents.1712572260.5987425793bc.2443.130  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/losses_validation_loss/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/losses_validation_loss/events.out.tfevents.1712572258.5987425793bc.2443.114  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_median/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_median/events.out.tfevents.1712572258.5987425793bc.2443.117  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_std/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_std/events.out.tfevents.1712572585.5987425793bc.2443.138  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_size/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_size/events.out.tfevents.1712572585.5987425793bc.2443.139  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_mean/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_mean/events.out.tfevents.1712572260.5987425793bc.2443.129  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_size/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_size/events.out.tfevents.1712572260.5987425793bc.2443.131  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_max/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_max/events.out.tfevents.1712572258.5987425793bc.2443.119  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_min/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_min/events.out.tfevents.1712572258.5987425793bc.2443.115  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_q3/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_q3/events.out.tfevents.1712572585.5987425793bc.2443.135  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_q1/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_q1/events.out.tfevents.1712572585.5987425793bc.2443.133  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_size/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_size/events.out.tfevents.1712572259.5987425793bc.2443.122  \n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/events.out.tfevents.1712572258.5987425793bc.2443.113  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_q1/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_q1/events.out.tfevents.1712572260.5987425793bc.2443.125  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_q1/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_q1/events.out.tfevents.1712572258.5987425793bc.2443.116  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_q3/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (train)_q3/events.out.tfevents.1712572260.5987425793bc.2443.127  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_q3/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (validation)_q3/events.out.tfevents.1712572258.5987425793bc.2443.118  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_min/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_min/events.out.tfevents.1712572585.5987425793bc.2443.132  \n",
            "   creating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_max/\n",
            "  inflating: cnn1d_no_filters/lightning_logs/version_0/squared_errors_stats (test)_max/events.out.tfevents.1712572585.5987425793bc.2443.136  \n",
            "Archive:  cnn1d_no_diffs.zip\n",
            "   creating: cnn1d_no_diffs/\n",
            "   creating: cnn1d_no_diffs/lightning_logs/\n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/\n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_median/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_median/events.out.tfevents.1712572587.5987425793bc.2443.154  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/losses_training_loss/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/losses_training_loss/events.out.tfevents.1712572587.5987425793bc.2443.151  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_max/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_max/events.out.tfevents.1712572587.5987425793bc.2443.156  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_std/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_std/events.out.tfevents.1712572586.5987425793bc.2443.149  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_min/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_min/events.out.tfevents.1712572587.5987425793bc.2443.152  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_mean/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_mean/events.out.tfevents.1712572586.5987425793bc.2443.148  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_mean/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_mean/events.out.tfevents.1712572917.5987425793bc.2443.165  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_median/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_median/events.out.tfevents.1712572917.5987425793bc.2443.162  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_std/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_std/events.out.tfevents.1712572587.5987425793bc.2443.158  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/losses_validation_loss/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/losses_validation_loss/events.out.tfevents.1712572586.5987425793bc.2443.142  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_median/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_median/events.out.tfevents.1712572586.5987425793bc.2443.145  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_std/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_std/events.out.tfevents.1712572917.5987425793bc.2443.166  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_size/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_size/events.out.tfevents.1712572917.5987425793bc.2443.167  \n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/events.out.tfevents.1712572586.5987425793bc.2443.141  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_mean/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_mean/events.out.tfevents.1712572587.5987425793bc.2443.157  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_size/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_size/events.out.tfevents.1712572587.5987425793bc.2443.159  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_max/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_max/events.out.tfevents.1712572586.5987425793bc.2443.147  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_min/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_min/events.out.tfevents.1712572586.5987425793bc.2443.143  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_q3/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_q3/events.out.tfevents.1712572917.5987425793bc.2443.163  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_q1/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_q1/events.out.tfevents.1712572917.5987425793bc.2443.161  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_size/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_size/events.out.tfevents.1712572586.5987425793bc.2443.150  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_q1/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_q1/events.out.tfevents.1712572587.5987425793bc.2443.153  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q1/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q1/events.out.tfevents.1712572586.5987425793bc.2443.144  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_q3/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (train)_q3/events.out.tfevents.1712572587.5987425793bc.2443.155  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q3/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q3/events.out.tfevents.1712572586.5987425793bc.2443.146  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_min/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_min/events.out.tfevents.1712572917.5987425793bc.2443.160  \n",
            "   creating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_max/\n",
            "  inflating: cnn1d_no_diffs/lightning_logs/version_0/squared_errors_stats (test)_max/events.out.tfevents.1712572917.5987425793bc.2443.164  \n",
            "Archive:  cnn1d_with_filters.zip\n",
            "   creating: cnn1d_with_filters/\n",
            "   creating: cnn1d_with_filters/lightning_logs/\n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/\n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_median/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_median/events.out.tfevents.1712572919.5987425793bc.2443.182  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/losses_training_loss/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/losses_training_loss/events.out.tfevents.1712572919.5987425793bc.2443.179  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_max/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_max/events.out.tfevents.1712572919.5987425793bc.2443.184  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_std/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_std/events.out.tfevents.1712572917.5987425793bc.2443.177  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_min/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_min/events.out.tfevents.1712572919.5987425793bc.2443.180  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_mean/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_mean/events.out.tfevents.1712572917.5987425793bc.2443.176  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_mean/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_mean/events.out.tfevents.1712573265.5987425793bc.2443.193  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_median/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_median/events.out.tfevents.1712573265.5987425793bc.2443.190  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_std/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_std/events.out.tfevents.1712572919.5987425793bc.2443.186  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/losses_validation_loss/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/losses_validation_loss/events.out.tfevents.1712572917.5987425793bc.2443.170  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_median/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_median/events.out.tfevents.1712572917.5987425793bc.2443.173  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_std/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_std/events.out.tfevents.1712573265.5987425793bc.2443.194  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_size/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_size/events.out.tfevents.1712573265.5987425793bc.2443.195  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_mean/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_mean/events.out.tfevents.1712572919.5987425793bc.2443.185  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_size/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_size/events.out.tfevents.1712572919.5987425793bc.2443.187  \n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/events.out.tfevents.1712572917.5987425793bc.2443.169  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_max/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_max/events.out.tfevents.1712572917.5987425793bc.2443.175  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_min/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_min/events.out.tfevents.1712572917.5987425793bc.2443.171  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_q3/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_q3/events.out.tfevents.1712573265.5987425793bc.2443.191  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_q1/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_q1/events.out.tfevents.1712573265.5987425793bc.2443.189  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_size/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_size/events.out.tfevents.1712572917.5987425793bc.2443.178  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_q1/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_q1/events.out.tfevents.1712572919.5987425793bc.2443.181  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_q1/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_q1/events.out.tfevents.1712572917.5987425793bc.2443.172  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_q3/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (train)_q3/events.out.tfevents.1712572919.5987425793bc.2443.183  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_q3/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (validation)_q3/events.out.tfevents.1712572917.5987425793bc.2443.174  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_min/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_min/events.out.tfevents.1712573265.5987425793bc.2443.188  \n",
            "   creating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_max/\n",
            "  inflating: cnn1d_with_filters/lightning_logs/version_0/squared_errors_stats (test)_max/events.out.tfevents.1712573265.5987425793bc.2443.192  \n",
            "Archive:  cnn1d_with_diffs.zip\n",
            "   creating: cnn1d_with_diffs/\n",
            "   creating: cnn1d_with_diffs/lightning_logs/\n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/events.out.tfevents.1712573266.5987425793bc.2443.197  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_median/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_median/events.out.tfevents.1712573267.5987425793bc.2443.210  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/losses_training_loss/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/losses_training_loss/events.out.tfevents.1712573267.5987425793bc.2443.207  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_max/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_max/events.out.tfevents.1712573267.5987425793bc.2443.212  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_std/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_std/events.out.tfevents.1712573266.5987425793bc.2443.205  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_min/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_min/events.out.tfevents.1712573267.5987425793bc.2443.208  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_mean/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_mean/events.out.tfevents.1712573266.5987425793bc.2443.204  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_mean/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_mean/events.out.tfevents.1712573615.5987425793bc.2443.221  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_median/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_median/events.out.tfevents.1712573615.5987425793bc.2443.218  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_std/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_std/events.out.tfevents.1712573267.5987425793bc.2443.214  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/losses_validation_loss/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/losses_validation_loss/events.out.tfevents.1712573266.5987425793bc.2443.198  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_median/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_median/events.out.tfevents.1712573266.5987425793bc.2443.201  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_std/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_std/events.out.tfevents.1712573615.5987425793bc.2443.222  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_size/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_size/events.out.tfevents.1712573615.5987425793bc.2443.223  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_mean/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_mean/events.out.tfevents.1712573267.5987425793bc.2443.213  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_size/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_size/events.out.tfevents.1712573267.5987425793bc.2443.215  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_max/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_max/events.out.tfevents.1712573266.5987425793bc.2443.203  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_min/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_min/events.out.tfevents.1712573266.5987425793bc.2443.199  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_q3/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_q3/events.out.tfevents.1712573615.5987425793bc.2443.219  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_q1/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_q1/events.out.tfevents.1712573615.5987425793bc.2443.217  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_size/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_size/events.out.tfevents.1712573266.5987425793bc.2443.206  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_q1/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_q1/events.out.tfevents.1712573267.5987425793bc.2443.209  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q1/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q1/events.out.tfevents.1712573266.5987425793bc.2443.200  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_q3/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (train)_q3/events.out.tfevents.1712573267.5987425793bc.2443.211  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q3/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q3/events.out.tfevents.1712573266.5987425793bc.2443.202  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_min/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_min/events.out.tfevents.1712573615.5987425793bc.2443.216  \n",
            "   creating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_max/\n",
            "  inflating: cnn1d_with_diffs/lightning_logs/version_0/squared_errors_stats (test)_max/events.out.tfevents.1712573615.5987425793bc.2443.220  \n",
            "Archive:  cnn1d_stack_filters.zip\n",
            "   creating: cnn1d_stack_filters/\n",
            "   creating: cnn1d_stack_filters/lightning_logs/\n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/\n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_median/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_median/events.out.tfevents.1712573617.5987425793bc.2443.238  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/losses_training_loss/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/losses_training_loss/events.out.tfevents.1712573617.5987425793bc.2443.235  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_max/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_max/events.out.tfevents.1712573617.5987425793bc.2443.240  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_std/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_std/events.out.tfevents.1712573616.5987425793bc.2443.233  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_min/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_min/events.out.tfevents.1712573617.5987425793bc.2443.236  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_mean/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_mean/events.out.tfevents.1712573616.5987425793bc.2443.232  \n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/events.out.tfevents.1712573616.5987425793bc.2443.225  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_mean/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_mean/events.out.tfevents.1712573967.5987425793bc.2443.249  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_median/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_median/events.out.tfevents.1712573967.5987425793bc.2443.246  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_std/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_std/events.out.tfevents.1712573617.5987425793bc.2443.242  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/losses_validation_loss/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/losses_validation_loss/events.out.tfevents.1712573616.5987425793bc.2443.226  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_median/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_median/events.out.tfevents.1712573616.5987425793bc.2443.229  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_std/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_std/events.out.tfevents.1712573967.5987425793bc.2443.250  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_size/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_size/events.out.tfevents.1712573967.5987425793bc.2443.251  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_mean/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_mean/events.out.tfevents.1712573617.5987425793bc.2443.241  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_size/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_size/events.out.tfevents.1712573617.5987425793bc.2443.243  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_max/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_max/events.out.tfevents.1712573616.5987425793bc.2443.231  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_min/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_min/events.out.tfevents.1712573616.5987425793bc.2443.227  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_q3/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_q3/events.out.tfevents.1712573967.5987425793bc.2443.247  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_q1/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_q1/events.out.tfevents.1712573967.5987425793bc.2443.245  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_size/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_size/events.out.tfevents.1712573616.5987425793bc.2443.234  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_q1/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_q1/events.out.tfevents.1712573617.5987425793bc.2443.237  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_q1/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_q1/events.out.tfevents.1712573616.5987425793bc.2443.228  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_q3/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (train)_q3/events.out.tfevents.1712573617.5987425793bc.2443.239  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_q3/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (validation)_q3/events.out.tfevents.1712573616.5987425793bc.2443.230  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_min/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_min/events.out.tfevents.1712573967.5987425793bc.2443.244  \n",
            "   creating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_max/\n",
            "  inflating: cnn1d_stack_filters/lightning_logs/version_0/squared_errors_stats (test)_max/events.out.tfevents.1712573967.5987425793bc.2443.248  \n",
            "Archive:  cnn1d_stack_diffs.zip\n",
            "   creating: cnn1d_stack_diffs/\n",
            "   creating: cnn1d_stack_diffs/lightning_logs/\n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/\n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_median/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_median/events.out.tfevents.1712573969.5987425793bc.2443.266  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/losses_training_loss/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/losses_training_loss/events.out.tfevents.1712573969.5987425793bc.2443.263  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_max/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_max/events.out.tfevents.1712573969.5987425793bc.2443.268  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_std/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_std/events.out.tfevents.1712573968.5987425793bc.2443.261  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_min/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_min/events.out.tfevents.1712573969.5987425793bc.2443.264  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_mean/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_mean/events.out.tfevents.1712573968.5987425793bc.2443.260  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_mean/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_mean/events.out.tfevents.1712574317.5987425793bc.2443.277  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_median/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_median/events.out.tfevents.1712574317.5987425793bc.2443.274  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_std/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_std/events.out.tfevents.1712573969.5987425793bc.2443.270  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/losses_validation_loss/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/losses_validation_loss/events.out.tfevents.1712573968.5987425793bc.2443.254  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_median/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_median/events.out.tfevents.1712573968.5987425793bc.2443.257  \n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/events.out.tfevents.1712573968.5987425793bc.2443.253  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_std/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_std/events.out.tfevents.1712574317.5987425793bc.2443.278  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_size/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_size/events.out.tfevents.1712574317.5987425793bc.2443.279  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_mean/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_mean/events.out.tfevents.1712573969.5987425793bc.2443.269  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_size/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_size/events.out.tfevents.1712573969.5987425793bc.2443.271  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_max/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_max/events.out.tfevents.1712573968.5987425793bc.2443.259  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_min/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_min/events.out.tfevents.1712573968.5987425793bc.2443.255  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_q3/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_q3/events.out.tfevents.1712574317.5987425793bc.2443.275  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_q1/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_q1/events.out.tfevents.1712574317.5987425793bc.2443.273  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_size/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_size/events.out.tfevents.1712573968.5987425793bc.2443.262  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_q1/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_q1/events.out.tfevents.1712573969.5987425793bc.2443.265  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q1/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q1/events.out.tfevents.1712573968.5987425793bc.2443.256  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_q3/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (train)_q3/events.out.tfevents.1712573969.5987425793bc.2443.267  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q3/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (validation)_q3/events.out.tfevents.1712573968.5987425793bc.2443.258  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_min/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_min/events.out.tfevents.1712574317.5987425793bc.2443.272  \n",
            "   creating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_max/\n",
            "  inflating: cnn1d_stack_diffs/lightning_logs/version_0/squared_errors_stats (test)_max/events.out.tfevents.1712574317.5987425793bc.2443.276  \n"
          ]
        }
      ],
      "source": [
        "#!unzip ff_filters_errors.zip\n",
        "!unzip ff_diffs.zip\n",
        "!unzip ff_diffs_errors.zip\n",
        "!unzip cnn1d_no_filters.zip\n",
        "!unzip cnn1d_no_diffs.zip\n",
        "!unzip cnn1d_with_filters.zip\n",
        "!unzip cnn1d_with_diffs.zip\n",
        "!unzip cnn1d_stack_filters.zip\n",
        "!unzip cnn1d_stack_diffs.zip"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
